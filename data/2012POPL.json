conference({
	"DataRevision": 2,
	"Event": "POPL 2012",
	"Name": "POPL 2012",
	"VenueInfo" : {
		"Name": "Sheraton Society Hotel",
		"GPS": {"Latitude": 39.946052, "Longitude": -75.144017}   
	}, 	
	"HotelInfo" : {
		"Telephone": "+112152386000"
	},
	"InfoPage": {
		"xaml": "foo",
		"Elements": [
			{
				"XamlName": "HotelMap",
				"Type": "Map",
				"GPS": {"Latitude": 39.946052, "Longitude": -75.144017}, 
				"MapLabel": "Sheraton Society Hotel"
			},
			{
				"XamlName": "LicenseButton",
				"Type": "WebLink",
				"URL": "http://research.microsoft.com/en-US/projects/confapp/terms.aspx"
			},
			{
				"XamlName": "PrivacyButton",
				"Type": "WebLink",
				"URL": "http://privacy.microsoft.com/en-us/default.msp"
			}
		]
	},
	"SessionPriorities" : [
                    "Award", "Invited Talk",  "Other"],	"Items": [
{
  "Title": "Or-Parallel Prolog Execution on Multicores Based on Stack Splitting",
  "Type": "Paper",
  "Key": "damp1",
  "Authors": ["Rui Vieira", "Ricardo Rocha", "Fernando Silva"],
  "Affiliations": ["CRACS & INESC TEC, Faculty of Sciences, University of Porto"],
  "Abstract": "Many or-parallel Prolog computational models exploiting implicit parallelism have been proposed in the past. The Muse and YapOr systems are arguably two of the most efficient systems exploiting or-parallelism on shared memory architectures, both based on the environment copying model. Stack splitting emerged as an alternative model specially geared to distributed memory architectures as it basically splits the computation in such a way that no further, or just minimal, synchronization is required. \n\n With the new multicore architectures, it just makes sense to recover the body of knowledge there is in this area and reengineer prior computational models to evaluate their performance on newer architectures. In this paper, we focus on the design and implementation of stack splitting in the YapOr system. Our aim is to take advantage of its robustness to efficiently implement stack splitting support using shared memory, and then be able to directly compare the original YapOr with the YapOr using stack splitting. We consider two splitting models, vertical splitting and half splitting, and have adapted data structures, scheduling and incremental copy procedures in YapOr to cope with the new models. Experimental results, on a multicore machine with 24 cores, show that YapOr using stack splitting is, in general, comparable to the original YapOr, obtaining in some cases better performance than with only environment copying."
},
{
  "Title": "Controlling Loops in Parallel Mercury Code",
  "Type": "Paper",
  "Key": "damp2",
  "Authors": ["Paul Bone", "Zoltan Somogyi", "Peter Schachte"],
  "Affiliations": ["The University of Melbourne & National ICT Australia (NICTA)", "The University of Melbourne"],
  "Abstract": "Recently we built a system that uses profiling data to automatically parallelize Mercury programs by finding conjunctions with expensive conjuncts that can run in parallel with minimal synchronization delays. This worked very well in many cases, but in cases of tail recursion, we got much lower speedups than we expected, due to excessive memory usage. In this paper, we present a novel program transformation that eliminates this problem, and also allows recursive calls inside parallel conjunctions to take advantage of tail recursion optimization. Our benchmark results show that our new transformation greatly increases the speedups we can get from parallel Mercury programs; in one case, it changes no speedup into almost perfect speedup on four cores."
},
{
  "Title": "Expressive Array Constructs in an Embedded GPU Kernel Programming Language",
  "Type": "Paper",
  "Key": "damp3",
  "Authors": ["Koen Claessen", "Mary Sheeran", "Bo Svensson"],
  "Affiliations": ["Chalmers University of Technology"],
  "Abstract": "Graphics Processing Units (GPUs) are powerful computing devices that with the advent of CUDA/OpenCL are becomming useful for general purpose computations. Obsidian is an embedded domain specific language that generates CUDA kernels from functional descriptions. A symbolic array construction allows us to guarantee that intermediate arrays are fused away. However, the current array construction has some drawbacks; in particular, arrays cannot be combined efficiently. We add a new type of push arrays to the existing Obsidian system in order to solve this problem. The two array types complement each other, and enable the definition of combinators that both take apart and combine arrays, and that result in efficient generated code. This extension to Obsidian is demonstrated on a sequence of sorting kernels, with good results. The case study also illustrates the use of combinators for expressing the structure of parallel algorithms. The work presented is preliminary, and the combinators presented must be generalised. However, the raw speed of the generated kernels bodes well."
},
{
  "Title": "Programmable Data Dependencies and Placements",
  "Type": "Paper",
  "Key": "damp4",
  "Authors": ["Eva Burrows", "Magne Haveraaen"],
  "Affiliations": ["University of Bergen"],
  "Abstract": "One of the major issues in parallelizing applications is to deal with the inherent dependency structure of the program. Dependence analysis provides execution-order constraints between program statements, and can establish legitimate ways to carry out program code transformations. The concept of data dependency constitutes one class of dependencies obtained through dependence analysis, a form related to data parallelism. Since automatic dependence analysis has proved to be too complex for the general case, parallelizing compilers cannot help parallelizing every dependency pattern. \n\nIn many cases, the data dependency pattern of a computation is independent from the actual data values, i.e., it is static, though the pattern may scale with the size of the data set. \n\nIn this paper, we explore how a static, scalable data dependency can be presented to the compiler in a meaningful way. We describe the major components of a proposed framework in which static and possibly scalable data dependencies are turned into programmable entities. The framework provides a high, and easy to manipulate, level to deal with data distribution and placement of computations onto any parallel system which has a well defined space-time communication structure. The data dependency information together with the placement information can be utilised by a compiler to generate parallel code. This presentation explores the idea of programmable data placements in more detail through concrete examples for the CUDA API of Nvidia GPUs."
},
{
  "Title": "Multi-DaC Programming Model",
  "Type": "Paper",
  "Key": "damp5s",
  "Authors": ["Abdorreza Savadi", "Morteza Moradi", "Hossein Deldari"],
  "Affiliations": ["Ferdowsi University of Mashhad (FUM)", "Islamic Azad University-Mashhad Branch (IAUM)"],
  "Abstract": "Nowadays, the evolution of multi-core architectures goes towards increasing the number of cores and levels of cache. Meanwhile, current typical parallel programming models are unable to exploit the potential of these processors efficiently. In order to achieve desired performance on these hardwares we need to understand architectural parameters appropriately and also apply them in algorithm design. Computational models such as Multi-BSP, illustrate these parameters and explain adequate methods for designing algorithms on multi-cores. One of the most applicable categories of problems is Divide-and-Conquer (DaC) that needs to be adapted by such model for implementing on these systems. In this paper, we have attempted to make a mapping between DaC tree and the Memory Hierarchy (MH) of multi-core processor. Multi-BSP model inspired us to introduce Multi-DaC programming model. Analogous to Multi-BSP analysis, lower bounds for communication and synchronization costs have been presented in the paper respecting DaC algorithms. This work is a step towards making multi-core programming easy and tries to obtain correct analysis of DaC algorithm behavior on multi-core architectures."
},
{
  "Title": "Sessional Dataflow",
  "Type": "Paper",
  "Key": "damp7s",
  "Authors": ["Dominic Duggan", "Jianhua Yao"],
  "Affiliations": ["Stevens Institute of Technology"],
  "Abstract": "The purpose of sessional dataflow is to provide a compositional semantics for dataflow computations that can be scheduled at compile-time. The interesting issues arise in enforcing static flow requirements in the composition of actors, ensuring that input and output rates of actors on related channels match, and that cycles in the composition of actors do not introduce deadlock. Ultimately the purpose of sessional dataflow is to support dynamic operations on subnets, ensuring that assumptions underlying static scheduling are not violated by operations such as subnet update and reconfiguration. This account focuses on a simplified case of sessional dataflow, to draw out the key points of the approach."
},
{
  "Title": "Compilers must speak properties, not just code",
  "Type": "Paper",
  "Key": "damp9s",
  "Authors": ["Raimund Kirner", "Frank Penczek", "Alex Shafarenko"],
  "Affiliations": ["University of Hertfordshire"],
  "Abstract": "This is a work-in-progress presentation in which we will argue that approaches based on components coordinated declaratively, such as S-Net, are ideally placed for automatic multicore optimisation. We will present our case for a component compiler producing not only object code, but also symbolic constraints describing the functional, and more importantly extra-functional, properties of the source component, such as computational complexity, resource and configuration requirements. We also argue that if the coordination language is well structured, which is easily achievable when it is declarative, it is possible to aggregate the constraints yielded by the components stage-wise and to represent the multicore optimisation problem in standard CSP form to use general-purpose constraint solvers. The use of symbolic constraints to describe system behaviour is shown by some examples of S-Net network combinators. If successful our approach will achieve an unprecedented degree of flexibility in programming for a wide range of heterogeneous multi-/many-core architectures. We would like to initiate a discussion on the interplay of constraint solving and declarative coordination programming."
},
{
  "Title": "Polynomial-Time Inverse Computation for Accumulative Functions with Multiple Data Traversals",
  "Type": "Paper",
  "Key": "pepm01",
  "Authors": ["Kazutaka Matsuda", "Kazuhiro Inaba", "Keisuke Nakano"],
  "Affiliations": ["Tohoku University", "National Institute of Informatics", "The University of Electro-Communications"],
  "Abstract": "Inverse computation has many applications such as serialization/deserialization, providing support for undo, and test-case generation for software testing. In this paper, we propose an inverse computation method that always terminates for a class of functions known as parameter-linear macro tree transducers, which involve multiple data traversals and the use of accumulations. The key to our method is the observation that a function in the class can be regarded as a non-accumulative context-generating transformation without multiple data traversals. Accordingly, we demonstrate that it is easy to achieve terminating inverse computation for the class by context-wise memoization of the inverse computation results. We also show that when we use a tree automaton to express the inverse computation results, the inverse computation runs in time polynomial to the size of the original output and the textual program size."
},
{
  "Title": "Functional Programs as Compressed Data",
  "Type": "Paper",
  "Key": "pepm02",
  "Authors": ["Naoki Kobayashi", "Kazutaka Matsuda", "Ayumi Shinohara"],
  "Affiliations": ["Tohoku University"],
  "Abstract": "We propose an application of programming language techniques to lossless data compression, where tree data are compressed as functional programs that generate them. This 'functional programs as compressed data' approach has several advantages. First, it follows from the standard argument of Kolmogorov complexity that the size of compressed data can be optimal up to an additive constant. Secondly, a compression algorithm is clean. it is just a sequence of beta-expansions for lambda-terms. Thirdly, one can use program verification and transformation techniques (higher-order model checking, in particular) to apply certain operations on data without decompression. In the paper, we present algorithms for data compression and manipulation based on the approach, and prove their correctness. We also report preliminary experiments on prototype data compression/transformation systems."
},
{
  "Title": "An Approach to Completing Variable Names for Implicitly Typed Functional Languages",
  "Type": "Paper",
  "Key": "pepm03",
  "Authors": ["Takumi Goto", "Isao Sasano"],
  "Affiliations": ["Shibaura Institute of Technology"],
  "Abstract": "This paper presents an approach to completing variable names when writing programs in implicitly typed functional languages. As a first step toward developing practical systems, we considered a simple case. up to the cursor position the program text is given completely. With this assumption we specify a variable completion problem for an implicitly typed core functional language with let-polymorphism and show an algorithm for solving the problem. Based on the algorithm we have implemented a variable name completion system for the language as an Emacs-mode."
},
{
  "Title": "The Interaction of Contracts and Laziness",
  "Type": "Paper",
  "Key": "pepm04",
  "Authors": ["Markus Degen", "Peter Thiemann", "Stefan Wehr"],
  "Affiliations": ["University of Freiburg"],
  "Abstract": "Contract monitoring for strict higher-order functional languages has an intuitive meaning, an established theoretical basis, and a standard implementation. For lazy functional languages, the situation is less clear-cut. There2 is no agreed-upon intended meaning or theory, and there are competing implementations with subtle semantic differences. \n\nThis paper proposes meaning preservation and completeness as formally defined properties for evaluating implementations of contract monitoring. Both properties have simple definitions that are straightforward to check. A survey of existing implementations reveals that some are meaning preserving, some are complete, and some have neither property. The main result is that contract monitoring for lazy functional languages cannot be complete and meaning preserving at the same time, although both properties can be achieved in isolation."
},
{
  "Title": "Hybrid Contract Checking via Symbolic Simplification",
  "Type": "Paper",
  "Key": "pepm05",
  "Authors": ["Dana Xu"],
  "Affiliations": ["INRIA"],
  "Abstract": "Program errors are hard to detect or prove absent. Allowing programmers to write formal and precise specifications, especially in the form of contracts, is a popular approach to program verification and error discovery. We formalize and implement a hybrid (static and dynamic) contract checker for a subset of OCaml. The key technique is symbolic simplification, which makes integrating static and dynamic contract checking easy and effective. Our technique statically checks contract satisfaction or blames the function violating the contract. When a contract satisfaction is undecidable, it leaves residual code for dynamic contract checking."
},
{
  "Title": "Incremental Resource Usage Analysis",
  "Type": "Paper",
  "Key": "pepm06",
  "Authors": ["Elvira Albert", "Jesús Correas", "Germán Puebla", "Guillermo Román-Díez"],
  "Affiliations": ["Complutense University of Madrid", "Technical University of Madrid"],
  "Abstract": "The aim of incremental global analysis is, given a program, its analysis results and a series of changes to the program, to obtain the new analysis results as efficiently as possible and, ideally, without having to (re-)analyze fragments of code which are not affected by the changes. incremental analysis can significantly reduce both the time and the memory requirements of analysis. This paper presents an incremental resource usage analysis for a sequential Java-like language. Our main contributions are (1) a multi-domain incremental fixed-point algorithm which can be used by all global pre-analyses required to infer the cost (including class, sharing, cyclicity, constancy, and size analyses), and which takes care of propagating dependencies among such domains, and (2) a novel form of cost summaries which allows us to incrementally reconstruct only those components of cost functions affected by the change. Experimental results in the COSTA system show that the proposed incremental analysis performs very efficiently in practice."
},
{
  "Title": "Obfuscation by Partial Evaluation of Distorted Interpreters",
  "Type": "Paper",
  "Key": "pepm07",
  "Authors": ["Roberto Giacobazzi", "Neil Jones", "Isabella Mastroeni"],
  "Affiliations": ["University of Verona", "University of Copenhagen"],
  "Abstract": "How to construct a general program obfuscator? We present a novel approach to automatically generating obfuscated code P2 from any program P whose source code is given. Start with a (program-executing) interpreter interp for the language in which P is written. Then distort interp so it is still correct, but its specialization P2 w.r.t. P is transformed code that is equivalent to the original program, but harder to understand or analyze. Potency of the obfuscator is proved with respect to a general model of the attacker, modeled as an approximate (abstract) interpreter. A systematic approach to distortion is to make program P obscure by transforming it to P2 on which (abstract) interpretation is incomplete. Interpreter distortion can be done by making residual in the specialization process sufficiently many interpreter operations to defeat an attacker in extracting sensible information from transformed code. Our method is applied to. code flattening, data-type obfuscation, and opaque predicate insertion. The technique is language independent and can be exploited for designing obfuscating compilers."
},
{
  "Title": "Well-typed Narrowing with Extra Variables in Functional-Logic Programming",
  "Type": "Paper",
  "Key": "pepm08",
  "Authors": ["Francisco López-Fraguas", "Enrique Martin-Martin", "Juan Rodríguez-Hortalá"],
  "Affiliations": ["Universidad Complutense de Madrid"],
  "Abstract": "Narrowing is the usual computation mechanism in functional-logic programming (FLP), where bindings for free variables are found at the same time that expressions are reduced. These free variables may be already present in the goal expression, but they can also be introduced during computations by the use of program rules with extra variables. However, it is known that narrowing in FLP generates problems from the point of view of types, problems that can only be avoided using type information at run-time. Nevertheless, most FLP systems use static typing based on Damas-Milner type system and they do not carry any type information in execution, thus ill-typed reductions may be performed in these systems. In this paper we prove, using the let-narrowing relation as the operational mechanism, that types are preserved in narrowing reductions provided the substitutions used preserve types. Based on this result, we prove that types are also preserved in narrowing reductions without type checks at run-time when higher order (HO) variable bindings are not performed and most general unifiers are used in unifications, for programs with transparent patterns. Then we characterize a restricted class of programs for which no binding of HO variables happens in reductions, identifying some problems encountered in the definition of this class. To conclude, we use the previous results to show that a simulation of needed narrowing via program transformation also preserves types."
},
{
  "Title": "Distillation with Labelled Transition Systems",
  "Type": "Paper",
  "Key": "pepm09",
  "Authors": ["Geoffrey Hamilton", "Neil Jones"],
  "Affiliations": ["Dublin City University", "University of Copenhagen"],
  "Abstract": "In this paper, we provide an improved basis for the 'distillation' program transformation. It is known that superlinear speedups can be obtained using distillation, but cannot be obtained by other earlier automatic program transformation techniques such as deforestation, positive supercompilation and partial evaluation. We give distillation an improved semantic basis, and explain how superlinear speedups can occur."
},
{
  "Title": "An Analytical Inductive Functional Programming System that Avoids Unintended Programs",
  "Type": "Paper",
  "Key": "pepm10b",
  "Authors": ["Susumu Katayama"],
  "Affiliations": ["University of Miyazaki"],
  "Abstract": "Inductive functional programming (IFP) is a research field extending from software science to artificial intelligence that deals with functional program synthesis based on generalization from ambiguous specifications, usually given as input-output example pairs. Currently, the approaches to IFP can be categorized into two general groups. the analytical approach that is based on analysis of the input-output example pairs, and the generate-and-test approach that is based on generation and testing of many candidate programs. The analytical approach shows greater promise for application to greater problems because the search space is restricted by the given example set, but it requires much more examples written in orderto yield results that reflect the user's intention, which is bother- some and causes the algorithm to slow down. On the other hand, the generate-and-test approach does not require long description of input-output examples, but does not restrict the search space using the example set. This paper proposes a new approach taking the best of the two, called analytically-generate-and-test approach, which is based on analytical generation and testing of many pro- gram candidates. For generating many candidate programs, the pro- posed system uses a new variant of I GOR II, the exemplary analyt- ical inductive functional programming algorithm. This new system preserves the efficiency features of analytical approaches, while minimizing the possibility of generating unintended programs even when using fewer input-output examples."
},
{
  "Title": "Composing Transformations for Instrumentation and Optimization",
  "Type": "Paper",
  "Key": "pepm11",
  "Authors": ["Michael Gorbovitski", "Yanhong Liu", "Scott Stoller", "Tom Rothamel"],
  "Affiliations": ["State University of New York at Stony Brook"],
  "Abstract": "When transforming programs for complex instrumentation and optimization, it is essential to understand the effect of the transformations, to best optimize the transformed programs, and to speedup the transformation process. This paper describes a powerful method for composing transformation rules to achieve these goals. \n\nWe specify the transformations declaratively as instrumentation rules and invariant rules, the latter for transforming complex queries in instrumentation and in programs into efficient incremental computations. Our method automatically composes the transformation rules and optimizes the composed rules before applying the optimized composed rules. The method allows (1) the effect of transformations to be accumulated in composed rules and thus easy to see, (2) the replacements in composed rules to be optimized without the difficulty of achieving the optimization on large transformed programs, and (3) the transformation process to be sped up by applying a composed rule in one pass of program analyses and transformations instead of applying the original rules in multiple passes. \n\nWe have implemented the method for Python. We successfully used it for instrumentation, in ranking peers in BitTorrent; and for optimization of complex queries, in the instrumentation of BitTorrent, in evaluating connections of network hosts using NetFlow, and in generating efficient implementations of Constrained RBAC."
},
{
  "Title": "Streams that Compose using Macros that Oblige",
  "Type": "Paper",
  "Key": "pepm12",
  "Authors": ["Martin Hirzel", "Bugra Gedik"],
  "Affiliations": ["IBM Watson Research Center"],
  "Abstract": "Since the end of frequency scaling, the programming languages community has started to embrace multi-core and even distributed systems. One paradigm that lends itself well to distribution is stream processing. In stream processing, an application consists of a directed graph of streams and operators, where streams are infinite sequences of data items, and operators fire in infinite loops to process data. This model directly exposes parallelism, requires no shared memory, and is a good match for several emerging application domains. Unfortunately, streaming languages have so far been lacking in abstraction. This paper introduces higher-order composite operators, which encapsulate stream subgraphs, and contracts, which specify pre- and post-conditions for composites. Composites are expanded at compile time, in a manner similar to macros. Their contractual obligations are also checked at compile-time. We build on existing work on macros and contracts to implement higher-order composites. The user-visible language features provide a consistent look-and-feel for the streaming language, whereas the underlying implementation provides high-quality static error messages and prevents accidental name capture."
},
{
  "Title": "Translating Flowcharts to Non-Deterministic Languages",
  "Type": "Paper",
  "Key": "pepm13",
  "Authors": ["Surinder Jain", "Chenyi Zhang", "Bernhard Scholz"],
  "Affiliations": ["The University of Sydney", "University of Queensland"],
  "Abstract": "Modeling languages are used to verify software and can be classified into deterministic modeling languages and non-deterministic modeling languages. Deterministic modeling languages have a single thread of control whereas non-deterministic ones have a multitude of threads of control and are more amenable for program transformations and analyses. However, deterministic languages such as control-flow graphs are pre-dominantly used in programming language tools. \n\nIn this work, we translate programs in a deterministic flowchart language to a non-deterministic algebraic modelling language. For the translation, we employ the technique of converting a finite state automata to a regular expression. The states of the finite state automata represent states in the control-flow graph, and the edges represent the edges in the control-flowgraph. We construct a homomorphism to show that the translation is sound, i.e., we prove that the semantics of the program in the deterministic flowchart language is preserved in the translation. Experiments on our implemented algorithm are conducted on the SPEC benchmark suite."
},
{
  "Title": "StagedSAC: A Case Study in Performance-Oriented DSL Development",
  "Type": "Paper",
  "Key": "pepm14b",
  "Authors": ["Vlad Ureche", "Tiark Rompf", "Arvind Sujeeth", "Hassan Chafi", "Martin Odersky"],
  "Affiliations": ["EPFL", "Stanford"],
  "Abstract": "Domain-specific languages (DSLs) can bridge the gap between high-level programming and efficient execution. However, implementing compiler tool-chains for performance oriented DSLs requires significant effort. Recent research has produced methodologies and frameworks that promise to reduce this development effort by enabling quick transition from library-only, purely embedded DSLs to optimizing compilation. \n\nIn this case study we report on our experience implementing a compiler for StagedSAC. StagedSAC is a DSL for arithmetic processing with multidimensional arrays modeled after the stand-alone language SAC (Single Assignment C). The main language feature of both SAC and StagedSAC is a loop construction that enables high-level and concise implementations of array algorithms. At the same time, the functional semantics of the two languages allow for advanced compiler optimizations and parallel code generation. \n\nWe describe how we were able to quickly evolve from a pure library DSL to a performance-oriented compiler with a good speedup and only minor syntax changes using the technique of Lightweight Modular Staging. We also describe the optimizations we perform to obtain fast code and how we plan to generate parallel code with minimal effort using the Delite framework."
},
{
  "Title": "Compiling Math to Fast Code",
  "Type": "Paper",
  "Key": "pepm1pm",
  "Authors": ["Markus Püschel"],
  "Affiliations": ["ETH Zürich"],
  "Abstract": "Extracting optimal performance from modern computing platforms has become increasingly difficult over the last few years. The effect is particularly noticeable in computations that are of mathematical nature such as those needed in multimedia processing, communication, control, graphics, and scientific simulations. a straightforward implementation, e.g., in C, is often one or two orders of magnitude slower than the best possible code. The reason is in optimizations that are known to be difficult and often impossible for compilers. parallelization, vectorization, and locality optimizations. \n\nOn the other hand, many mathematical applications spend most of their runtime in well-defined mathematical kernels such as matrix computations, Fourier transforms, interpolation, coding, and others. Since these are likely to be needed for decades to come, it makes sense to build program generation systems for their automatic production. The input for the generator would be only the algorithm knowledge in a suitable representation and some information about the computing platform. The output of the generator is highly optimized, platform-tuned code. For new platforms, the code is regenerated; for new types of platforms, the generator is expanded rather than rewriting the actual kernel code. \n\nWith Spiral we have built such a system for the domain of linear transforms. In this talk we give a brief survey on the key techniques underlying Spiral. a domain specific mathematical language, rewriting systems for different forms of parallelization and to compute the so-called recursion step closure to improve locality in recursive code, and the use of machine learning to adapt code at installation time. Spiral-generated code has proven to be as good as, and sometimes faster, than any human-written code. As one example, Spiral has been used to generate part of Intel's commercial libraries IPP and MKL."
},
{
  "Title": "Ideas for Connecting Inductive Program Synthesis and Bidirectionalization",
  "Type": "Paper",
  "Key": "pepm21s",
  "Authors": ["Janis Voigtländer"],
  "Affiliations": ["University of Bonn"],
  "Abstract": "We share a vision of connecting the topics of bidirectional transformation and inductive program synthesis, by proposing to use the latter in approaching problematic aspects of the former. This research perspective does not present accomplished results, rather opening discussion and describing experiments designed to explore the potential of inductive program synthesis for bidirectionalization (the act of automatically producing a backwards from a forwards transformation), in particular to address the issue of integrating programmer intentions and expectations."
},
{
  "Title": "Towards Typing for Small-Step Direct Reflection",
  "Type": "Paper",
  "Key": "pepm22s",
  "Authors": ["Jacques Carette", "Aaron Stump"],
  "Affiliations": ["McMaster University", "The University of Iowa"],
  "Abstract": "Direct reflection is a form of meta-programming in which program terms can intensionally analyze other program terms. Previous work defined a big-step semantics for a directly reflective language called Archon, with a conservative approach to variable scoping based on operations for opening a lambda-abstraction and swapping the order of nested lambda-abstractions. In this short paper, we give a small-step semantics for a revised version of Archon, based on operations for opening and closing lambda abstractions. We then discuss challenges for designing a static type system for this language, which is our ultimate goal."
},
{
  "Title": "Specification and Verification of Meta-Programs",
  "Type": "Paper",
  "Key": "pepm2mb",
  "Authors": ["Martin Berger"],
  "Affiliations": ["University of Sussex"],
  "Abstract": "This talk gives an overview of meta-programming, with an emphasis on recent developments in extending existing specification and verification technology to meta-programs."
},
{
  "Title": "Scala-Virtualized",
  "Type": "Paper",
  "Key": "pepm31t",
  "Authors": ["Adriaan Moors", "Tiark Rompf", "Philipp Haller", "Martin Odersky"],
  "Affiliations": ["EPFL", "EPFL and Stanford"],
  "Abstract": "Scala-Virtualized extends the Scala language to better support hosting embedded DSLs. Embedding a DSL in Scala-Virtualized comes with all the benefits of a shallow embedding thanks to Scala's flexible syntax, without giving up analyzing and manipulating the domain program -- typically exclusive to deep embeddings. Through lightweight modular staging, implemented in standard Scala, the benefits of a deep embedding are recovered with little overhead. Scala-Virtualized lifts more of the language's built-in constructs and static information to complete this support and make it more convenient. We illustrate how Scala-Virtualized makes Scala an even better host for embedded DSLs along three axes of customizing the language. syntax, run-time behavior and static semantics."
},
{
  "Title": "Finding and Fixing Java Naming Bugs with the Lancelot Eclipse Plugin",
  "Type": "Paper",
  "Key": "pepm32t",
  "Authors": ["Edvard Karlsen", "Einar Høst", "Bjarte Østvold"],
  "Affiliations": ["Sør-Trøndelag University College", "Computas AS", "Norwegian Computing Center"],
  "Abstract": "The Lancelot plugin extends the integrated development environment Eclipse with support for finding and fixing `naming bugs' in Java programs. A naming bug is a mismatch between the name and implementation of a method, in the sense that the pairing of name and implementation do not correspond to the implicit method naming conventions used by many well-known open source applications. \n\nLancelot has not been presented before, but its theoretical foundations and evaluation have been published. The contribution of the present paper is to present a publicly available tool building on our theory, explain the design of the tool, including some necessary adaptations to the interactive use setting, and report on our experience with it. The source code of Lancelot is available under an open source license."
},
{
  "Title": "COSTABS: A Cost and Termination Analyzer for ABS",
  "Type": "Paper",
  "Key": "pepm33t",
  "Authors": ["Elvira Albert", "Puri Arenas", "Samir Genaim", "Miguel Gómez-Zamalloa", "Germán Puebla"],
  "Affiliations": ["Complutense University of Madrid", "Technical University of Madrid"],
  "Abstract": "ABS is an abstract behavioural specification language to model distributed concurrent systems. Characteristic features of ABS are that. (1) it allows abstracting from implementation details while remaining executable. a functional sub-language over abstract data types is used to specify internal, sequential computations; and (2) the imperative sub-language provides flexible concurrency and synchronization mechanisms by means of asynchronous method calls, release points in method definitions, and cooperative scheduling of method activations. This paper presents COSTABS, a COSt and Termination analyzer for ABS, which is able to prove termination and obtain resource usage bounds for both the imperative and functional fragments of programs. The resources that COSTABS can infer include termination, number of execution steps, memory consumption, number of asynchronous calls, among others. The analysis bounds provide formal guarantees that the execution of the program will never exceed the inferred amount of resources. The system can be downloaded as free software from its web site, where a repository of examples and a web interface are also provided. To the best of our knowledge, COSTABS is the first system able to perform resource analysis for a concurrent language."
},
{
  "Title": "LTL Types FRP",
  "Type": "Paper",
  "Key": "plpv01",
  "Authors": ["Alan Jeffrey"],
  "Affiliations": ["Alcatel-Lucent"],
  "Abstract": "Functional Reactive Programming (FRP) is a form of reactive programming whose model is pure functions over signals. FRP is often expressed in terms of arrows with loops, which is the type class for a Freyd category (that is a premonoidal category with a cartesian centre) equipped with a premonoidal trace. This type system suffices to define the dataflow structure of a reactive program, but does not express its temporal properties. In this paper, we show that Linear-time Temporal Logic (LTL) is a natural extension of the type system for FRP, which constrains the temporal behaviour of reactive programs. We show that a constructive LTL can be defined in a dependently typed functional language, and that reactive programs form proofs of constructive LTL properties. In particular, implication in LTL gives rise to stateless functions on streams, and the 'constrains' modality gives rise to causal functions. We show that reactive programs form a partially traced monoidal category, and hence can be given as a form of arrows with loops, where the type system enforces that only decoupled functions can be looped."
},
{
  "Title": "A Hoare Calculus for the Verification of Synchronous Languages",
  "Type": "Paper",
  "Key": "plpv03",
  "Authors": ["Manuel Gesell", "Klaus Schneider"],
  "Affiliations": ["TU Kaiserslautern"],
  "Abstract": "The synchronous model of computation divides the execution of a program into macro steps that consist of finitely many atomic micro steps (like assignments). The micro steps of a macro step are executed within the same variable environment (i.e. in parallel) but all updates to the variables are synchronously performed at the level of macro steps. The availability of a formally defined semantics allows one to use formal methods for the verification of synchronous programs. To this end, model checking is already widely used for synchronous programs, but the use of interactive verification e.g. by using a Hoare calculus, is only in its infancies. One reason for this situation is that the assignment rule of the classic Hoare calculus implicitly defines a sequential programming model which is only a special case of the synchronous model of computation. \n\nIn this paper, we therefore suggest a generalization of the classic Hoare calculus to deal with synchronous programs. The main idea is thereby that the assignment rule refers to all assignments made in a macro step so that the synchronous model of computation is axiomatized. It is possible to rewrite all synchronous programs so that the assignments of every macro step are collected in a single tuple assignment. This way, our generalization of the assignment rule is applicable to arbitrary synchronous programs. We present non-trivial case studies that show the feasibility of our approach."
},
{
  "Title": "Formal Network Packet Processing with Minimal Fuss",
  "Type": "Paper",
  "Key": "plpv05",
  "Authors": ["Reynald Affeldt", "David Nowak", "Yutaka Oiwa"],
  "Affiliations": ["National Institute of Advanced Industrial Science and Technology"],
  "Abstract": "An error in an Internet protocol or its implementation is rarely benign. at best, it leads to malfunctions, at worst, to security holes. These errors are all the more likely that the official documentation for Internet protocols (the RFCs) is written in natural language. To prevent ambiguities and pave the way to formal verification of Internet protocols and their implementations, we advocate formalization of RFCs in a proof-assistant. As a first step towards this goal, we propose in this paper to use invertible syntax descriptions to formalize network packet processing. Invertible syntax descriptions consist in a library of combinators that can be used interchangeably as parsers or pretty-printers. network packet processing specified this way is not only unambiguous, it can also be turned into a trustful reference implementation, all the more trustful that there is no risk for inconsistencies between the parser and the pretty-printer. Concretely, we formalize invertible syntax descriptions in the Coq proof-assistant and extend them to deal with data-dependent constraints, an essential feature when it comes to parsing network packets. The usefulness of our formalization is demonstrated with an application to TLS, the protocol on which e-commerce relies."
},
{
  "Title": "The VerCors Project - Setting Up Basecamp",
  "Type": "Paper",
  "Key": "plpv08",
  "Authors": ["Afshin Amighi", "Stefan Blom", "Marieke Huisman", "Marina Zaharieva-Stojanovski"],
  "Affiliations": ["University of Twente", "University of Twente and Dundalk Institute of Technology"],
  "Abstract": "This paper describes the first results and on-going work in the VerCors project. The VerCors project is about Verification of Concurrent Data Structures. Its goal is to develop a specification language and program logic for concurrent programs, and in particular for concurrent data structures, as these are the essential building blocks of many different concurrent programs. The program logic is based on our earlier work on permission-based separation logic for Java. This is an extension of Hoare logic that is particularly convenient to reason about concurrent programs. \n\n The paper first describes the tool set that is currently being built to support reasoning with this logic. It supports a specification language that combines features of separation logic with JML. For the verification, the program and its annotations are encoded into Chalice, and then we reuse the Chalice translation to Boogie to generate the proof obligations. \n\n Next, the paper describes our first results on data structure specifications. We use histories to keep track of the changes to the data structures, and we show how these histories allow us to derive other conclusions about the data structure implementations. We also discuss how we plan to reason about volatile variables, and how we will use this to verify lock-free data structures. \n\n Throughout the paper, we discuss our plans for future work within the VerCors project."
},
{
  "Title": "Equational Reasoning about Programs with General Recursion and Call-by-value Semantics",
  "Type": "Paper",
  "Key": "plpv10",
  "Authors": ["Garrin Kimmell", "Aaron Stump", "Harley Eades", "Peng Fu", "Tim Sheard", "Stephanie Weirich", "Chris Casinghino", "Vilhelm Sjoberg", "Nathan Collins", "Ki Yung Ahn"],
  "Affiliations": ["University of Iowa", "University of iowa", "Portland State University", "University of Pennsylvania"],
  "Abstract": "Dependently typed programming languages provide a mechanism for integrating verification and programming by encoding invariants as types. Traditionally, dependently typed languages have been based on constructive type theories, where the connection between proofs and programs is based on the Curry-Howard correspondence. This connection comes at a price, however, as it is necessary for the languages to be normalizing to preserve logical soundness. Trellys is a call-by-value dependently typed programming language currently in development that is designed to integrate a type theory with unsound programming features, such as general recursion, Type.Type, and others. In this paper we outline one core language design for Trellys, and demonstrate the use of the key language constructs to facilitate sound reasoning about potentially unsound programs."
},
{
  "Title": "Dependent Interoperability",
  "Type": "Paper",
  "Key": "plpv12",
  "Authors": ["Peter-Michael Osera", "Vilhelm Sjöberg", "Steve Zdancewic"],
  "Affiliations": ["University of Pennsylvania"],
  "Abstract": "In this paper we study the problem of interoperability --- combining constructs from two separate programming languages within one program --- in the case where one of the two languages is dependently typed and the other is simply typed.We present a core calculus called SD, which combines dependently- and simply-typed sub-languages and supports user-defined (dependent) datatypes, among other standard features. SD has boundary terms that mediate the interaction between the two sub-languages. The operational semantics of SD demonstrates how the necessary dynamic checks, which must be done when passing a value from the simply-typed world to the dependently typed world, can be extracted from the dependent type constructors themselves, modulo user-defined functions for marshaling values across the boundary.We establish type-safety and other meta-theoretic properties of SD, and contrast this approach to others in the literature."
},
{
  "Title": "Reflexive Toolbox for Regular Expression Matching",
  "Type": "Paper",
  "Key": "plpv13",
  "Authors": ["Vladimir Komendantsky"],
  "Affiliations": ["University of St Andrews"],
  "Abstract": "We study a derivative method allowing to prove termination of computations on regular expressions. A Coq formalisation of a canonical non-deterministic finite automaton construction on a regular expression is presented. The correctness of the functional definitions is formally verified in Coq using the libraries and the small-scale reflection tools of Ssreflect. We propose to extend the proofs further, and this is a work in progress, to study termination of containment and equivalence in terms of partial derivatives. This serves as a major motivation and intended application of the presented approach. A method that we develop in the paper, called shadowing, allows for a smooth program extraction from decision procedures whatever the complexity of the dependently typed proofs."
},
{
  "Title": "Verification Challenges of Pervasive Information Flow",
  "Type": "Paper",
  "Key": "plpv21v",
  "Authors": ["Benjamin Pierce"],
  "Affiliations": ["University of Pennsylvania"],
  "Abstract": "The CRASH/SAFE project aims to design a new computer system that is highly resistant to cyber-attack. It offers a rare opportunity to rethink the hardware / OS / software stack from a completely clean slate, unhampered by legacy constraints. We are building novel hardware, a new high-level programming language, and a suite of modern operating system services, all embodying fundamental security principles -- separation of privilege, least privilege, mutual suspicion, etc. -- down to their very bones. Achieving these goals demands a co-design methodology in which all system layers are designed together, with a ruthless insistence on simplicity, security, and verifiability at every level. \n\nI will describe the current state of the CRASH/SAFE design and discuss some of the most interesting verification challenges that it raises."
},
{
  "Title": "Multiple Facets for Dynamic Information Flow",
  "Type": "Paper",
  "Key": "popl002",
  "Authors": ["Thomas Austin", "Cormac Flanagan"],
  "Affiliations": ["University of California, Santa Cruz"],
  "Abstract": "JavaScript has become a central technology of the web, but it is also the source of many security problems, including cross-site scripting attacks and malicious advertising code. Central to these problems is the fact that code from untrusted sources runs with full privileges. We implement information flow controls in Firefox to help prevent violations of data confidentiality and integrity. Most previous information flow techniques have primarily relied on either static type systems, which are a poor fit for JavaScript, or on dynamic analyses that sometimes get stuck due to problematic implicit flows, even in situations where the target web application correctly satisfies the desired security policy. We introduce faceted values, a new mechanism for providing information flow security in a dynamic manner that overcomes these limitations. Taking inspiration from secure multi-execution, we use faceted values to simultaneously and efficiently simulate multiple executions for different security levels, thus providing non-interference with minimal overhead, and without the reliance on the stuck executions of prior dynamic approaches."
},
{
  "Title": "A Unified Approach to Fully Lazy Sharing",
  "Type": "Paper",
  "Key": "popl018",
  "Authors": ["Thibaut Balabonski"],
  "Affiliations": ["Univ Paris Diderot, Sorbonne Paris Cité, PPS, UMR 7126, CNRS"],
  "Abstract": "We give an axiomatic presentation of sharing-via-labelling for weak lambda-calculi, that makes it possible to formally compare many different approaches to fully lazy sharing, and obtain two important results. We prove that the known implementations of full laziness are all equivalent in terms of the number of beta-reductions performed, although they behave differently regarding the duplication of terms. We establish a link between the optimality theories of weak lambda-calculi and first-order rewriting systems by expressing fully lazy lambda-lifting in our framework, thus emphasizing the first-order essence of weak reduction."
},
{
  "Title": "An Executable Formal Semantics of C with Applications",
  "Type": "Paper",
  "Key": "popl027",
  "Authors": ["Chucky Ellison", "Grigore Rosu"],
  "Affiliations": ["University of Illinois"],
  "Abstract": "This paper describes an executable formal semantics of C. Being executable, the semantics has been thoroughly tested against the GCC torture test suite and successfully passes 99.2% of 776 test programs. It is the most complete and thoroughly tested formal definition of C to date. The semantics yields an interpreter, debugger, state space search tool, and model checker 'for free'. The semantics is shown capable of automatically finding program errors, both statically and at runtime. It is also used to enumerate nondeterministic behavior."
},
{
  "Title": "Defining Code-injection Attacks",
  "Type": "Paper",
  "Key": "popl041",
  "Authors": ["Donald Ray", "Jay Ligatti"],
  "Affiliations": ["University of South Florida"],
  "Abstract": "This paper shows that existing definitions of code-injection attacks (e.g., SQL-injection attacks) are flawed. The flaws make it possible for attackers to circumvent existing mechanisms, by supplying code-injecting inputs that are not recognized as such. The flaws also make it possible for benign inputs to be treated as attacks. After describing these flaws in conventional definitions of code-injection attacks, this paper proposes a new definition, which is based on whether the symbols input to an application get used as (normal-form) values in the application's output. Because values are already fully evaluated, they cannot be considered 'code' when injected. This simple new definition of code-injection attacks avoids the problems of existing definitions, improves our understanding of how and when such attacks occur, and enables us to evaluate the effectiveness of mechanisms for mitigating such attacks."
},
{
  "Title": "The Marriage of Bisimulations and Kripke Logical Relations",
  "Type": "Paper",
  "Key": "popl044",
  "Authors": ["Chung-Kil Hur", "Derek Dreyer", "Georg Neis", "Viktor Vafeiadis"],
  "Affiliations": ["MPI-SWS"],
  "Abstract": "There has been great progress in recent years on developing effective techniques for reasoning about program equivalence in ML-like languages---that is, languages that combine features like higher-order functions, recursive types, abstract types, and general mutable references. Two of the most prominent types of techniques to have emerged are *bisimulations* and *Kripke logical relations (KLRs)*. While both approaches are powerful, their complementary advantages have led us and other researchers to wonder whether there is an essential tradeoff between them. Furthermore, both approaches seem to suffer from fundamental limitations if one is interested in scaling them to inter-language reasoning. \n\nIn this paper, we propose *relation transition systems (RTSs)*, which marry together some of the most appealing aspects of KLRs and bisimulations. In particular, RTSs show how bisimulations' support for reasoning about recursive features via *coinduction* can be synthesized with KLRs' support for reasoning about local state via *state transition systems*. Moreover, we have designed RTSs to avoid the limitations of KLRs and bisimulations that preclude their generalization to inter-language reasoning. Notably, unlike KLRs, RTSs are transitively composable."
},
{
  "Title": "Recursive Proofs for Inductive Tree Data-Structures",
  "Type": "Paper",
  "Key": "popl052",
  "Authors": ["Madhusudan Parthasarathy", "Xiaokang Qiu", "Andrei Stefanescu"],
  "Affiliations": ["University of Illinois at Urbana-Champaign"],
  "Abstract": "We develop logical mechanisms and procedures to facilitate the verification of full functional properties of inductive tree data-structures using recursion that are sound, incomplete, but terminating. Our contribution rests in a new extension of first-order logic with recursive definitions called Dryad, a syntactical restriction on pre- and post-conditions of recursive imperative programs using Dryad, and a systematic methodology for accurately unfolding the footprint on the heap uncovered by the program that leads to finding simple recursive proofs using formula abstraction and calls to SMT solvers. We evaluate our methodology empirically and show that several complex tree data-structure algorithms can be checked against full functional specifications automatically, given pre- and post-conditions. This results in the first automatic terminating methodology for proving a wide variety of annotated algorithms on tree data-structures correct, including max-heaps, treaps, red-black trees, AVL trees, binomial heaps, and B-trees."
},
{
  "Title": "An Abstract Interpretation Framework for Termination",
  "Type": "Paper",
  "Key": "popl061",
  "Authors": ["Patrick Cousot", "Radhia Cousot"],
  "Affiliations": ["CNRS, Ecole Normale Superieure, and INRIA, France and Courant Institute, NYU, USA", "CNRS, Ecole Normale Superieure, and INRIA, France"],
  "Abstract": "Proof, verification and analysis methods for termination all rely on two induction principles. (1) a variant function or induction on data ensuring progress towards the end and (2) some form of induction on the program structure. \n\nThe abstract interpretation design principle is first illustrated for the design of new forward and backward proof, verification and analysis methods for safety. The safety collecting semantics defining the strongest safety property of programs is first expressed in a constructive fixpoint form. Safety proof and checking/verification methods then immediately follow by fixpoint induction. Static analysis of abstract safety properties such as invariance are constructively designed by fixpoint abstraction (or approximation) to (automatically) infer safety properties. So far, no such clear design principle did exist for termination so that the existing approaches are scattered and largely not comparable with each other. \n\nFor (1), we show that this design principle applies equally well to po- tential and definite termination. The trace-based termination collecting semantics is given a fixpoint definition. Its abstraction yields a fixpoint definition of the best variant function. By further abstraction of this best variant function, we derive the Floyd/Turing termination proof method as well as new static analysis methods to effectively compute approxima- tions of this best variant function. \n\nFor (2), we introduce a generalization of the syntactic notion of struc- tural induction (as found in Hoare logic) into a semantic structural induc- tion based on the new semantic concept of inductive trace cover covering execution traces by segments, a new basis for formulating program prop- erties. Its abstractions allow for generalized recursive proof, verification and static analysis methods by induction on both program structure, con- trol, and data. Examples of particular instances include Floyd's handling of loop cut-points as well as nested loops, Burstall's intermittent asser- tion total correctness proof method, and Podelski-Rybalchenko transition invariants."
},
{
  "Title": "Algebraic Foundations for Effect-Dependent Optimisations",
  "Type": "Paper",
  "Key": "popl062",
  "Authors": ["Ohad Kammar", "Gordon Plotkin"],
  "Affiliations": ["University of Edinburgh"],
  "Abstract": "We present a general theory of Gifford-style type and effect annotations, where effect annotations are sets of effects. Generality is achieved by recourse to the theory of algebraic effects, a development of Moggi's monadic theory of computational effects that emphasises the operations causing the effects at hand and their equational theory. The key observation is that annotation effects can be identified with operation symbols. \n\nWe develop an annotated version of Levy's Call-by-Push-Value language with a kind of computations for every effect set; it can be thought of as a sequential, annotated intermediate language. We develop a range of validated optimisations (i.e., equivalences), generalising many existing ones and adding new ones. We classify these optimisations as structural, algebraic, or abstract. structural optimisations always hold; algebraic ones depend on the effect theory at hand; and abstract ones depend on the global nature of that theory (we give modularly-checkable sufficient conditions for their validity)."
},
{
  "Title": "Higher-Order Functional Reactive Programming in Bounded Space",
  "Type": "Paper",
  "Key": "popl074",
  "Authors": ["Neelakantan Krishnaswami", "Nick Benton", "Jan Hoffmann"],
  "Affiliations": ["Max Planck Institute for Software Systems", "Microsoft Research", "Yale University"],
  "Abstract": "Functional reactive programming (FRP) is an elegant and successful approach to programming reactive systems declaratively. The high levels of abstraction and expressivity that make FRP attractive as a programming model do, however, often lead to programs whose resource usage is excessive and hard to predict. \n\nIn this paper, we address the problem of space leaks in discrete-time functional reactive programs. We present a functional reactive programming language that statically bounds the size of the dataflow graph a reactive program creates, while still permitting use of higher-order functions and higher-type streams such as streams of streams. We achieve this with a novel linear type theory that both controls allocation and ensures that all recursive definitions are well-founded. \n\nWe also give a denotational semantics for our language by combining recent work on metric spaces for the interpretation of higher-order causal functions with length-space models of space-bounded computation. The resulting category is doubly closed and hence forms a model of the logic of bunched implications."
},
{
  "Title": "Randomized Accuracy-Aware Program Transformations For Efficient Approximate Computations",
  "Type": "Paper",
  "Key": "popl075",
  "Authors": ["Zeyuan Zhu", "Sasa Misailovic", "Jonathan Kelner", "Martin Rinard"],
  "Affiliations": ["MIT"],
  "Abstract": "Despite the fact that approximate computations have come to dominate many areas of computer science, the field of program transformations has focused almost exclusively on traditional semantics-preserving transformations that do not attempt to exploit the opportunity, available in many computations, to acceptably trade off accuracy for benefits such as increased performance and reduced resource consumption. \n\nWe present a model of computation for approximate computations and an algorithm for optimizing these computations. The algorithm works with two classes of transformations. substitution transformations (which select one of a number of available implementations for a given function, with each implementation offering a different combination of accuracy and resource consumption) and sampling transformations (which randomly discard some of the inputs to a given reduction). The algorithm produces a (1+epsilon) randomized approximation to the optimal randomized computation (which minimizes resource consumption subject to a probabilistic accuracy specification in the form of a maximum expected error or maximum error variance)."
},
{
  "Title": "Clarifying and Compiling C/C++ Concurrency: from C++11 to POWER",
  "Type": "Paper",
  "Key": "popl079",
  "Authors": ["Mark Batty", "Kayvan Memarian", "Scott Owens", "Susmit Sarkar", "Peter Sewell"],
  "Affiliations": ["University of Cambridge", "University of Cambridge & INRIA"],
  "Abstract": "The upcoming C and C++ revised standards add concurrency to the languages, for the first time, in the form of a subtle *relaxed memory model* (the *C++11 model*). This aims to permit compiler optimisation and to accommodate the differing relaxed-memory behaviours of mainstream multiprocessors, combining simple semantics for most code with high-performance *low-level atomics* for concurrency libraries. \n\nIn this paper, we first establish two simpler but provably equivalent models for C++11, one for the full language and another for the subset without consume operations. Subsetting further to the fragment without low-level atomics, we identify a subtlety arising from atomic initialisation and prove that, under an additional condition, the model is equivalent to sequential consistency for race-free programs. \n\nWe then prove our main result, the correctness of two proposed compilation schemes for the C++11 load and store concurrency primitives to Power assembly, having noted that an earlier proposal was flawed. (The main ideas apply also to ARM, which has a similar relaxed memory architecture.) \n\nThis should inform the ongoing development of production compilers for C++11 and C1x, clarifies what properties of the machine architecture are required, and builds confidence in the C++11 and Power semantics."
},
{
  "Title": "A Compiler and Run-time System for Network Programming Languages",
  "Type": "Paper",
  "Key": "popl086",
  "Authors": ["Christopher Monsanto", "Nate Foster", "Rob Harrison", "David Walker"],
  "Affiliations": ["Princeton University", "Cornell University", "United States Military Academy"],
  "Abstract": "Software-defined networks (SDNs) are a new kind of network architecture in which a controller machine manages a distributed collection of switches by instructing them to install or uninstall packet-forwarding rules and report traffic statistics. The recently formed Open Networking Consortium, whose members include Google, Facebook, Microsoft, Verizon, and others, hopes to use this architecture to transform the way that enterprise and data center networks are implemented. \n\n In this paper, we define a high-level, declarative language, called NetCore, for expressing packet-forwarding policies on SDNs. NetCore is expressive, compositional, and has a formal semantics. To ensure that a majority of packets are processed efficiently on switches---instead of on the controller---we present new compilation algorithms for NetCore and couple them with a new run-time system that issues rule installation commands and traffic-statistics queries to switches. Together, the compiler and run-time system generate efficient rules whenever possible and outperform the simple, manual techniques commonly used to program SDNs today. In addition, the algorithms we develop are generic, assuming only that the packet-matching capabilities available on switches satisfy some basic algebraic laws. \n\n Overall, this paper delivers a new design for a high-level network programming language; an improved set of compiler algorithms; a new run-time system for SDN architectures; the first formal semantics and proofs of correctness in this domain; and an implementation and evaluation that demonstrates the performance benefits over traditional manual techniques."
},
{
  "Title": "Information Effects",
  "Type": "Paper",
  "Key": "popl087",
  "Authors": ["Roshan James", "Amr Sabry"],
  "Affiliations": ["Indiana University"],
  "Abstract": "Computation is a physical process which, like all other physical processes, is fundamentally reversible. From the notion of type isomorphisms, we derive a typed, universal, and reversible computational model in which information is treated as a linear resource that can neither be duplicated nor erased. We use this model as a semantic foundation for computation and show that the ``gap'' between conventional irreversible computation and logically reversible computation can be captured by a type-and-effect system. Our type-and-effect system is structured as an arrow metalanguage that exposes creation and erasure of information as explicit effect operations. Irreversible computations arise from interactions with an implicit information environment, thus making them a derived notion, much like open systems in Physics. We sketch several applications which can benefit from an explicit treatment of information effects, such as quantitative information-flow security and differential privacy."
},
{
  "Title": "A Language for Automatically Enforcing Privacy Policies",
  "Type": "Paper",
  "Key": "popl088",
  "Authors": ["Jean Yang", "Kuat Yessenov", "Armando Solar-Lezama"],
  "Affiliations": ["Massachusetts Institute of Technology"],
  "Abstract": "It is becoming increasingly important for applications to protect sensitive data. With current techniques, the programmer bears the burden of ensuring that the application's behavior adheres to policies about where sensitive values may flow. Unfortunately, privacy policies are difficult to manage because their global nature requires coordinated reasoning and enforcement. To address this problem, we describe a programming model that makes the system responsible for ensuring adherence to privacy policies. The programming model has two components. 1) core programs describing functionality independent of privacy concerns and 2) declarative, decentralized policies controlling how sensitive values are disclosed. Each sensitive value encapsulates multiple views; policies describe which views are allowed based on the output context. The system is responsible for automatically ensuring that outputs are consistent with the policies. We have implemented this programming model in a new functional constraint language named Jeeves. In Jeeves, sensitive values are introduced as symbolic variables and policies correspond to constraints that are resolved at output channels. We have implemented Jeeves as a Scala library using an SMT solver as a model finder. In this paper we describe the dynamic and static semantics of Jeeves and the properties about policy enforcement that the semantics guarantees. We also describe our experience implementing a conference management system and a social network."
},
{
  "Title": "Static and User-Extensible Proof Checking",
  "Type": "Paper",
  "Key": "popl089",
  "Authors": ["Antonis Stampoulis", "Zhong Shao"],
  "Affiliations": ["Yale University"],
  "Abstract": "Despite recent successes, large-scale proof development within proof assistants remains an arcane art that is extremely time-consuming. We argue that this can be attributed to two profound shortcomings in the architecture of modern proof assistants. The first is that proofs need to include a large amount of minute detail; this is due to the rigidity of the proof checking process, which cannot be extended with domain-specific knowledge. In order to avoid these details, we rely on developing and using tactics, specialized procedures that produce proofs. Unfortunately, tactics are both hard to write and hard to use, revealing the second shortcoming of modern proof assistants. This is because there is no static knowledge about their expected use and behavior. \n\nAs has recently been demonstrated, languages that allow type-safe manipulation of proofs, like Beluga, Delphin and VeriML, can be used to partly mitigate this second issue, by assigning rich types to tactics. Still, the architectural issues remain. In this paper, we build on this existing work, and demonstrate two novel ideas. an extensible conversion rule and support for static proof scripts. Together, these ideas enable us to support both user-extensible proof checking, and sophisticated static checking of tactics, leading to a new point in the design space of future proof assistants. Both ideas are based on the interplay between a light-weight staging construct and the rich type information available."
},
{
  "Title": "A Rely-Guarantee-Based Simulation for Verifying Concurrent Program Transformations",
  "Type": "Paper",
  "Key": "popl093",
  "Authors": ["Hongjin Liang", "Xinyu Feng", "Ming Fu"],
  "Affiliations": ["University of Science and Technology of China"],
  "Abstract": "Verifying program transformations usually requires proving that the resulting program (the target) refines or is equivalent to the original one (the source). However, the refinement relation between individual sequential threads cannot be preserved in general with the presence of parallel compositions, due to instruction reordering and the different granularities of atomic operations at the source and the target. On the other hand, the refinement relation defined based on fully abstract semantics of concurrent programs assumes arbitrary parallel environments, which is too strong and cannot be satisfied by many well-known transformations. In this paper, we propose a Rely-Guarantee-based Simulation (RGSim) to verify concurrent program transformations. The relation is parametrized with constraints of the environments that the source and the target programs may compose with. It considers the interference between threads and their environments, thus is less permissive than relations over sequential programs. It is compositional w.r.t. parallel compositions as long as the constraints are satisfied. Also, RGSim does not require semantics preservation under all environments, and can incorporate the assumptions about environments made by specific program transformations in the form of rely/guarantee conditions. We use RGSim to reason about optimizations and prove atomicity of concurrent objects. We also propose a general garbage collector verification framework based on RGSim, and verify the Boehm et al. concurrent mark-sweep GC."
},
{
  "Title": "A Type Theory for Probability Density Functions",
  "Type": "Paper",
  "Key": "popl098",
  "Authors": ["Sooraj Bhat", "Ashish Agarwal", "Richard Vuduc", "Alexander Gray"],
  "Affiliations": ["Georgia Institute of Technology", "New York University"],
  "Abstract": "There has been great interest in creating probabilistic programming languages to simplify the coding of statistical tasks; however, there still does not exist a formal language that simultaneously provides (1) continuous probability distributions, (2) the ability to naturally express custom probabilistic models, and (3) probability density functions (PDFs). This collection of features is necessary for mechanizing fundamental statistical techniques. We formalize the first probabilistic language that exhibits these features, and it serves as a foundational framework for extending the ideas to more general languages. Particularly novel are our type system for absolutely continuous (AC) distributions (those which permit PDFs) and our PDF calculation procedure, which calculates PDF s for a large class of AC distributions. Our formalization paves the way toward the rigorous encoding of powerful statistical reformulations."
},
{
  "Title": "Abstractions from Tests",
  "Type": "Paper",
  "Key": "popl103",
  "Authors": ["Mayur Naik", "Hongseok Yang", "Ghila Castelnuovo", "Mooly Sagiv"],
  "Affiliations": ["Georgia Institute of Technology", "University of Oxford", "Tel-Aviv University"],
  "Abstract": "We present a framework for leveraging dynamic analysis to find good abstractions for static analysis. A static analysis in our framework is parametrised. Our main insight is to directly and efficiently compute from a concrete trace, a necessary condition on the parameter configurations to prove a given query, and thereby prune the space of parameter configurations that the static analysis must consider. We provide constructive algorithms for two instance analyses in our framework. a flow- and context-sensitive thread-escape analysis and a flow- and context-insensitive points-to analysis. We show the efficacy of these analyses, and our approach, on six Java programs comprising two million bytecodes. the thread-escape analysis resolves 80% of queries on average, disproving 28% and proving 52%; the points-to analysis resolves 99% of queries on average, disproving 29% and proving 70%."
},
{
  "Title": "A Mechanized Semantics for C++ Object Construction and Destruction, with Applications to Resource Management",
  "Type": "Paper",
  "Key": "popl106",
  "Authors": ["Tahina Ramananandro", "Gabriel Dos Reis", "Xavier Leroy"],
  "Affiliations": ["INRIA Paris-Rocquencourt", "Texas A&M University"],
  "Abstract": "We present a formal operational semantics and its Coq mechanization for the C++ object model, featuring object construction and destruction, shared and repeated multiple inheritance, and virtual function call dispatch. These are key C++ language features for high-level system programming, in particular for predictable and reliable resource management. This paper is the first to present a formal mechanized account of the metatheory of construction and destruction in C++, and applications to popular programming techniques such as 'resource acquisition is initialization'. We also report on irregularities and apparent contradictions in the ISO C++03 and C++11 standards."
},
{
  "Title": "Programming with Binders and Indexed Data-Types",
  "Type": "Paper",
  "Key": "popl112",
  "Authors": ["Andrew Cave", "Brigitte Pientka"],
  "Affiliations": ["McGill University"],
  "Abstract": "We show how to combine a general purpose type system for an existing language with support for programming with binders and contexts by refining the type system of ML with a restricted form of dependent types where index objects are drawn from contextual LF. This allows the user to specify formal systems within the logical framework LF and index ML types with contextual LF objects. Our language design keeps the index language generic only requiring decidability of equality of the index language providing a modular design. To illustrate the elegance and effectiveness of our language, we give programs for closure conversion and normalization by evaluation. Our three key technical contribution are. 1) We give a bi-directional type system for our core language which is centered around refinement substitutions instead of constraint solving. As a consequence, type checking is decidable and easy to trust, although constraint solving may be undecidable. 2) We give a big-step environment based operational semantics with environments which lends itself to efficient implementation. 3) We prove our language to be type safe and have mechanized our theoretical development in the proof assistant Coq using the fresh approach to binding."
},
{
  "Title": "Analysis of Recursively Parallel Programs",
  "Type": "Paper",
  "Key": "popl115",
  "Authors": ["Ahmed Bouajjani", "Michael Emmi"],
  "Affiliations": ["Université Paris Diderot"],
  "Abstract": "We propose a general formal model of isolated hierarchical parallel computations, and identify several fragments to match the concurrency constructs present in real-world programming languages such as Cilk and X10. By associating fundamental formal models (vector addition systems with recursive transitions) to each fragment, we provide a common platform for exposing the relative difficulties of algorithmic reasoning. For each case we measure the complexity of deciding state-reachability for finite-data recursive programs, and propose algorithms for the decidable cases. The complexities which include PTIME, NP, EXPSPACE, and 2EXPTIME contrast with undecidable state-reachability for recursive multi-threaded programs."
},
{
  "Title": "Access Permission Contracts for Scripting Languages",
  "Type": "Paper",
  "Key": "popl121",
  "Authors": ["Phillip Heidegger", "Annette Bieniusa", "Peter Thiemann"],
  "Affiliations": ["University of Freiburg", "INRIA Paris-Rocquencourt and LIP6"],
  "Abstract": "The ideal software contract fully specifies the behavior of an operation. Often, in particular in the context of scripting languages, a full specification may be cumbersome to state and may not even be desired. In such cases, a partial specification, which describes selected aspects of the behavior, may be used to raise the confidence in an implementation of the operation to a reasonable level. \n\n We propose a novel kind of contract for object-based languages that specifies the side effects of an operation wth access permissions}. An access permission contract uses sets of access paths to express read and write permissions for the properties of the objects accessible from the operation. \n\n We specify a monitoring semantics for access permission contracts and implement this semantics in a contract system for JavaScript. We prove soundness and stability of violation under increasing aliasing for our semantics. \n\n Applications of access permission contracts include enforcing modularity, test-driven development, program understanding, and regression testing. With respect to testing and understanding, we find that adding access permissions to contracts increases the effectiveness of error detection through contract monitoring by 6-13%."
},
{
  "Title": "Canonicity for 2-Dimensional Type Theory",
  "Type": "Paper",
  "Key": "popl124",
  "Authors": ["Daniel Licata", "Robert Harper"],
  "Affiliations": ["Carnegie Mellon University"],
  "Abstract": "Higher-dimensional dependent type theory enriches conventional one-dimensional dependent type theory with additional structure expressing equivalence of elements of a type. This structure may be employed in a variety of ways to capture rather coarse identifications of elements, such as a universe of sets considered modulo isomorphism. Equivalence must be respected by all families of types and terms, as witnessed computationally by a type-generic program. Higher-dimensional type theory has applications to code reuse for dependently typed programming, and to the formalization of mathematics. In this paper, we develop a novel judgemental formulation of a two-dimensional type theory, which enjoys a canonicity property. a closed term of boolean type is definitionally equal to true or false. Canonicity is a necessary condition for a computational interpretation of type theory as a programming language, and does not hold for existing axiomatic presentations of higher-dimensional type theory. The method of proof is a generalization of the NuPRL semantics, interpreting types as syntactic groupoids rather than equivalence relations."
},
{
  "Title": "Freefinement",
  "Type": "Paper",
  "Key": "popl127",
  "Authors": ["Stephan van Staden", "Cristiano Calcagno", "Bertrand Meyer"],
  "Affiliations": ["ETH Zurich", "Imperial College London"],
  "Abstract": "Freefinement is an algorithm that constructs a sound refinement calculus from a verification system under certain conditions. In this paper, a verification system is any formal system for establishing whether an inductively defined term, typically a program, satisfies a specification. Examples of verification systems include Hoare logics and type systems. Freefinement first extends the term language to include specification terms, and builds a verification system for the extended language that is a sound and conservative extension of the original system. The extended system is then transformed into a sound refinement calculus. The resulting refinement calculus can interoperate closely with the verification system - it is even possible to reuse and translate proofs between them. Freefinement gives a semantics to refinement at an abstract level. it associates each term of the extended language with a set of terms from the original language, and refinement simply reduces this set. The paper applies freefinement to a simple type system for the lambda calculus and also to a Hoare logic."
},
{
  "Title": "Towards Nominal Computation",
  "Type": "Paper",
  "Key": "popl133",
  "Authors": ["Mikolaj Bojanczyk", "Laurent Braud", "Bartek Klin", "Slawomir Lasota"],
  "Affiliations": ["University of Warsaw"],
  "Abstract": "Nominal sets are a different kind of set theory, with a more relaxed notion of finiteness. They offer an elegant formalism for describing lambda-terms modulo alpha-conversion, or automata on data words. \n\nThis paper is an attempt at defining computation in nominal sets. We present a rudimentary programming language, called Nlambda. The key idea is that it includes a native type for finite sets in the nominal sense. To illustrate the power of our language, we write short programs that process automata on data words."
},
{
  "Title": "Resource-Sensitive Synchronization Inference by Abduction",
  "Type": "Paper",
  "Key": "popl147",
  "Authors": ["Matko Botincan", "Mike Dodds", "Suresh Jagannathan"],
  "Affiliations": ["University of Cambridge", "Purdue University"],
  "Abstract": "We present an analysis which takes as its input a sequential program, augmented with annotations indicating potential parallelization opportunities, and a sequential proof, written in separation logic, and produces a correctly-synchronized parallelized program and proof of that program. Unlike previous work, ours is not an independence analysis; we insert synchronization constructs to preserve relevant dependencies found in the sequential program that may otherwise be violated by a naive translation. Separation logic allows us to parallelize fine-grained patterns of resource-usage, moving beyond straightforward points-to analysis. \n\nOur analysis works by using the sequential proof to discover dependencies between different parts of the program. It leverages these discovered dependencies to guide the insertion of synchronization primitives into the parallelized program, and to ensure that the resulting parallelized program satisfies the same specification as the original sequential program, and exhibits the same sequential behaviour. Our analysis is built using frame inference and abduction, two techniques supported by an increasing number of separation logic tools."
},
{
  "Title": "Underspecified Harnesses and Interleaved Bugs",
  "Type": "Paper",
  "Key": "popl148",
  "Authors": ["Saurabh Joshi", "Shuvendu Lahiri", "Akash Lal"],
  "Affiliations": ["IIT Kanpur", "Microsoft Research"],
  "Abstract": "Static assertion checking of open programs requires setting up a precise harness to capture the environment assumptions. For instance, a library may require a file handle to be properly initialized before it is passed into it. A harness is used to set up or specify the appropriate preconditions before invoking methods from the program. In the absence of a precise harness, even the most precise automated static checkers are bound to report numerous false alarms. This often limits the adoption of static assertion checking in the hands of a user. \n\nIn this work, we explore the possibility of automatically filtering away (or prioritizing) warnings that result from imprecision in the harness. We limit our attention to the scenario when one is interested in finding bugs due to concurrency. We define a warning to be an interleaved bug when it manifests on an input for which no sequential interleaving produces a warning. As we argue in the paper, limiting a static analysis to only consider interleaved bugs greatly reduces false positives during static concurrency analysis in the presence of an imprecise harness. \n\nWe formalize interleaved bugs as a differential analysis between the original program and its sequential version and provide various techniques for finding them. Our implementation CBugs demonstrates that the scheme of finding interleaved bugs can alleviate the need to construct precise harnesses while checking real-life concurrent programs."
},
{
  "Title": "Constraints as Control",
  "Type": "Paper",
  "Key": "popl150",
  "Authors": ["Ali Sinan Köksal", "Viktor Kuncak", "Philippe Suter"],
  "Affiliations": ["Swiss Federal Institute of Technology (EPFL)"],
  "Abstract": "We present an extension of Scala that supports constraint programming over bounded and unbounded domains. The resulting language, Kaplan, provides the benefits of constraint programming while preserving the existing features of Scala. Kaplan integrates constraint and imperative programming by using constraints as an advanced control structure; the developers use the monadic 'for' construct to iterate over the solutions of constraints or branch on the existence of a solution. The constructs we introduce have simple semantics that can be understood as explicit enumeration of values, but are implemented more efficiently using symbolic reasoning. \n\nKaplan programs can manipulate constraints at run-time, with the combined benefits of type-safe syntax trees and first-class functions. The language of constraints is a functional subset of Scala, supporting arbitrary recursive function definitions over algebraic data types, sets, maps, and integers. \n\nOur implementation runs on a platform combining a constraint solver with a standard virtual machine. For constraint solving we use an algorithm that handles recursive function definitions through fair function unrolling and builds upon the state-of-the art SMT solver Z3. We evaluate Kaplan on examples ranging from enumeration of data structures to execution of declarative specifications. We found Kaplan promising because it is expressive, supporting a range of problem domains, while enabling full-speed execution of programs that do not rely on constraint programming."
},
{
  "Title": "Edit Lenses",
  "Type": "Paper",
  "Key": "popl153",
  "Authors": ["Martin Hofmann", "Benjamin Pierce", "Daniel Wagner"],
  "Affiliations": ["Ludwig-Maximilians-Universität München", "University of Pennsylvania"],
  "Abstract": "A lens is a bidirectional transformation between a pair of connected data structures, capable of translating an edit on one structure into an appropriate edit on the other. Many varieties of lenses have been studied, but none, to date, has offered a satisfactory treatment of how edits are represented. Many foundational accounts only consider edits of the form 'overwrite the whole structure,' leading to poor behavior in many situations by failing to track the associations between corresponding parts of the structures when elements are inserted and deleted in ordered lists, for example. Other theories of lenses do maintain these associations, either by annotating the structures themselves with change information or using auxiliary data structures, but every extant theory assumes that the entire original source structure is part of the information passed to the lens. \n\nWe offer a general theory of edit lenses, which work with descriptions of changes to structures, rather than with the structures themselves. We identify a simple notion of 'editable structure'--a set of states plus a monoid of edits with a partial monoid action on the states--and construct a semantic space of lenses between such structures, with natural laws governing their behavior. We show how a range of constructions from earlier papers on 'state-based' lenses can be carried out in this space, including composition, products, sums, list operations, etc. Further, we show how to construct edit lenses for arbitrary containers in the sense of Abbott, Altenkirch, and Ghani. Finally, we show that edit lenses refine a well-known formulation of state-based lenses, in the sense that every state-based lens gives rise to an edit lens over structures with a simple overwrite-only edit language, and conversely every edit lens on such structures gives rise to a state-based lens."
},
{
  "Title": "Sound Predictive Race Detection in Polynomial Time",
  "Type": "Paper",
  "Key": "popl167",
  "Authors": ["Yannis Smaragdakis", "Jacob Evans", "Caitlin Sadowski", "Jaeheon Yi", "Cormac Flanagan"],
  "Affiliations": ["University of Athens and University of Massachusetts", "University of Massachusetts", "University of California, Santa Cruz"],
  "Abstract": "Data races are among the most reliable indicators of programming errors in concurrent software. For at least two decades, Lamport's happens-before (HB) relation has served as the standard test for detecting races-other techniques, such as lockset-based approaches, fail to be sound, as they may falsely warn of races. This work introduces a new relation, causally-precedes (CP), which generalizes happens-before to observe more races without sacrificing soundness. Intuitively, CP tries to capture the concept of happens-before ordered events that must occur in the observed order for the program to observe the same values. What distinguishes CP from past predictive race detection approaches (which also generalize an observed execution to detect races in other plausible executions) is that CP-based race detection is both sound and of polynomial complexity. \n\nWe demonstrate that the unique aspects of CP result in practical benefit. Applying CP to real-world programs, we successfully analyze server-level applications (e.g., Apache FtpServer) and show that traces longer than in past predictive race analyses can be analyzed in mere seconds to a few minutes. For these programs, CP race detection uncovers races that are hard to detect by repeated execution and HB race detection. a single run of CP race detection produces several races not discovered by 10 separate rounds of happens-before race detection."
},
{
  "Title": "Symbolic Finite State Transducers: Algorithms and Applications",
  "Type": "Paper",
  "Key": "popl171",
  "Authors": ["Margus Veanes", "Pieter Hooimeijer", "Benjamin Livshits", "David Molnar", "Nikolaj Bjorner"],
  "Affiliations": ["Microsoft Research", "University of Virginia"],
  "Abstract": "Finite automata and finite transducers are used in a wide range of applications in software engineering, from regular expressions to specification languages. We extend these classic objects with symbolic alphabets represented as parametric theories. Admitting potentially infinite alphabets makes this representation strictly more general and succinct than classical finite transducers and automata over strings. Despite this, the main operations, including composition, checking that a transducer is single-valued, and equivalence checking for single-valued symbolic finite transducers are effective given a decision procedure for the background theory. We provide novel algorithms for these operations and extend composition to symbolic transducers augmented with registers. Our base algorithms are unusual in that they are nonconstructive, therefore, we also supply a separate model generation algorithm that can quickly find counterexamples in the case two symbolic finite transducers are not equivalent. The algorithms give rise to a complete decidable algebra of symbolic transducers. Unlike previous work, we do not need any syntactic restriction of the formulas on the transitions, only a decision procedure. In practice we leverage recent advances in satisfiability modulo theory (SMT) solvers. We demonstrate our techniques on four case studies, covering a wide range of applications. Our techniques can synthesize string pre-images in excess of 8,000 bytes in roughly a minute, and we find that our new encodings significantly outperform previous techniques in succinctness and speed of analysis."
},
{
  "Title": "Run Your Research: On the Effectiveness of Lightweight Mechanization",
  "Type": "Paper",
  "Key": "popl180",
  "Authors": ["Casey Klein", "John Clements", "Christos Dimoulas", "Carl Eastlund", "Matthias Felleisen", "Matthew Flatt", "Jay McCarthy", "Jon Rafkind", "Sam Tobin-Hochstadt", "Robert Findler"],
  "Affiliations": ["Northwestern University & PLT", "California Polytechnic State University & PLT", "Northeastern University & PLT", "University of Utah & PLT", "Brigham Young University & PLT", "Northwestern University"],
  "Abstract": "Formal models serve in many roles in the programming language community. In its primary role, a model communicates the idea of a language design; the architecture of a language tool; or the essence of a program analysis. No matter which role it plays, however, a faulty model doesn't serve its purpose. \n\nOne way to eliminate flaws from a model is to write it down in a mechanized formal language. It is then possible to state theorems about the model, to prove them, and to check the proofs. Over the past nine years, PLT has developed and explored a lightweight version of this approach, dubbed Redex. In a nutshell, Redex is a domain-specific language for semantic models that is embedded in the Racket programming language. The effort of creating a model in Redex is often no more burdensome than typesetting it with LaTeX; the difference is that Redex comes with tools for the semantics engineering life cycle."
},
{
  "Title": "On the Power of Coercion Abstraction",
  "Type": "Paper",
  "Key": "popl182",
  "Authors": ["Julien Cretin", "Didier Rémy"],
  "Affiliations": ["INRIA"],
  "Abstract": "Erasable coercions in System F-eta, also known as retyping functions, are well-typed eta-expansions of the identity. They may change the type of terms without changing their behavior and can thus be erased before reduction. Coercions in F-eta can model subtyping of known types and some displacement of quantifiers, but not subtyping assumptions nor certain forms of delayed type instantiation. We generalize F-eta by allowing abstraction over retyping functions. We follow a general approach where computing with coercions can be seen as computing in the lambda-calculus but keeping track of which parts of terms are coercions. We obtain a language where coercions do not contribute to the reduction but may block it and are thus not erasable. We recover erasable coercions by choosing a weak reduction strategy and restricting coercion abstraction to value-forms or by restricting abstraction to coercions that are polymorphic in their domain or codomain. The latter variant subsumes F-eta, F-sub, and MLF in a unified framework."
},
{
  "Title": "Towards a Program Logic for JavaScript",
  "Type": "Paper",
  "Key": "popl190",
  "Authors": ["Philippa Gardner", "Sergio Maffeis", "Gareth Smith"],
  "Affiliations": ["Imperial College"],
  "Abstract": "JavaScript has become the most widely used language for client-side web programming. The dynamic nature of JavaScript makes understanding its code notoriously difficult, leading to buggy programs and a lack of adequate static-analysis tools. We believe that logical reasoning has much to offer JavaScript. a simple description of program behaviour, a clear understanding of module boundaries, and the ability to verify security contracts. \n\nWe introduce a program logic for reasoning about a broad subset of JavaScript, including challenging features such as prototype inheritance and 'with'. We adapt ideas from separation logic to provide tractable reasoning about JavaScript code. reasoning about easy programs is easy; reasoning about hard programs is possible. We prove a strong soundness result. All libraries written in our subset and proved correct with respect to their specifications will be well-behaved, even when called by arbitrary JavaScript code."
},
{
  "Title": "Deciding Choreography Realizability",
  "Type": "Paper",
  "Key": "popl192",
  "Authors": ["Samik Basu", "Tevfik Bultan", "Meriem Ouederni"],
  "Affiliations": ["Iowa State University", "University of California, Santa Barbara", "University of Malaga"],
  "Abstract": "Since software systems are becoming increasingly more concurrent and distributed, modeling and analysis of interactions among their components is a crucial problem. In several application domains, message-based communication is used as the interaction mechanism, and the communication contract among the components of the system is specified semantically as a state machine. In the service-oriented computing domain such communication contracts are called 'choreography' specifications. A choreography specification identifies allowable ordering of message exchanges in a distributed system. A fundamental question about a choreography specification is determining its realizability, i.e., given a choreography specification, is it possible to build a distributed system that communicates exactly as the choreography specifies? Checking realizability of choreography specifications has been an open problem for several years and it was not known if this was a decidable problem. In this paper we give necessary and sufficient conditions for realizability of choreographies. We implemented the proposed realizability check and our experiments show that it can efficiently determine the realizability of 1) web service choreographies, 2) Singularity OS channel contracts, and 3) UML collaboration (communication) diagrams."
},
{
  "Title": "Nested Refinements: A Logic for Duck Typing",
  "Type": "Paper",
  "Key": "popl194",
  "Authors": ["Ravi Chugh", "Patrick Rondon", "Ranjit Jhala"],
  "Affiliations": ["University of California, San Diego"],
  "Abstract": "Programs written in dynamic languages make heavy use of features --- run-time type tests, value-indexed dictionaries, polymorphism, and higher-order functions --- that are beyond the reach of type systems that employ either purely syntactic or purely semantic reasoning. We present a core calculus, System D, that merges these two modes of reasoning into a single powerful mechanism of nested refinement types wherein the typing relation is itself a predicate in the refinement logic. System D coordinates SMT-based logical implication and syntactic subtyping to automatically typecheck sophisticated dynamic language programs. By coupling nested refinements with McCarthy's theory of finite maps, System D can precisely reason about the interaction of higher-order functions, polymorphism, and dictionaries. The addition of type predicates to the refinement logic creates a circularity that leads to unique technical challenges in the metatheory, which we solve with a novel stratification approach that we use to prove the soundness of System D."
},
{
  "Title": "The Ins and Outs of Gradual Type Inference",
  "Type": "Paper",
  "Key": "popl195",
  "Authors": ["Aseem Rastogi", "Avik Chaudhuri", "Basil Hosmer"],
  "Affiliations": ["Stony Brook University", "Adobe Systems"],
  "Abstract": "Gradual typing lets programmers evolve their dynamically typed programs by gradually adding explicit type annotations, which confer benefits like improved performance and fewer run-time failures. \n\nHowever, we argue that such evolution often requires a giant leap, and that type inference can offer a crucial missing step. If omitted type annotations are interpreted as unknown types, rather than the dynamic type, then static types can often be inferred, thereby removing unnecessary assumptions of the dynamic type. The remaining assumptions of the dynamic type may then be removed by either reasoning outside the static type system, or restructuring the code. \n\nWe present a type inference algorithm that can improve the performance of existing gradually typed programs without introducing any new run-time failures. To account for dynamic typing, types that flow in to an unknown type are treated in a fundamentally different manner than types that flow out. Furthermore, in the interests of backward-compatibility, an escape analysis is conducted to decide which types are safe to infer. We have implemented our algorithm for ActionScript, and evaluated it on the SunSpider and V8 benchmark suites. We demonstrate that our algorithm can improve the performance of unannotated programs as well as recover most of the type annotations in annotated programs."
},
{
  "Title": "A Type System for Borrowing Permissions",
  "Type": "Paper",
  "Key": "popl201",
  "Authors": ["Karl Naden", "Robert Bocchino", "Jonathan Aldrich", "Kevin Bierhoff"],
  "Affiliations": ["Carnegie Mellon University", "Two Sigma Investments"],
  "Abstract": "In object-oriented programming, unique permissions to object references are useful for checking correctness properties such as consistency of typestate and noninterference of concurrency. To be usable, unique permissions must be borrowed --- for example, one must be able to read a unique reference out of a field, use it for something, and put it back. While one can null out the field and later reassign it, this paradigm is ungainly and requires unnecessary writes, potentially hurting cache performance. Therefore, in practice borrowing must occur in the type system, without requiring memory updates. Previous systems support borrowing with external alias analysis and/or explicit programmer management of fractional permissions. While these approaches are powerful, they are also awkward and difficult for programmers to understand. We present an integrated language and type system with unique, immutable, and shared permissions, together with new local permissions that say that a reference may not be stored to the heap. Our system also includes change permissions such as unique>>unique and unique>>none that describe how permissions flow in and out of method formal parameters. Together, these features support common patterns of borrowing, including borrowing multiple local permissions from a unique reference and recovering the unique reference when the local permissions go out of scope, without any explicit management of fractions in the source language. All accounting of fractional permissions is done by the type system ``under the hood.'' We present the syntax and static and dynamic semantics of a formal core language and state soundness results. We also illustrate the utility and practicality of our design by using it to express several realistic examples."
},
{
  "Title": "Formalizing the LLVM Intermediate Representation for Verified Program Transformations",
  "Type": "Paper",
  "Key": "popl208",
  "Authors": ["Jianzhou Zhao", "Santosh Nagarakatte", "Milo Martin", "Steve Zdancewic"],
  "Affiliations": ["University of Pennsylvania"],
  "Abstract": "This paper presents Vellvm (verified LLVM), a framework for reasoning about programs expressed in LLVM's intermediate representation and transformations that operate on it. Vellvm provides a mechanized formal semantics of LLVM's intermediate representation, its type system, and properties of its SSA form. The framework is built using the Coq interactive theorem prover. It includes multiple operational semantics and proves relations among them to facilitate different reasoning styles and proof techniques. \n\nTo validate Vellvm's design, we extract an interpreter from the Coq formal semantics that can execute programs from LLVM test suite and thus be compared against LLVM reference implementations. To demonstrate Vellvm's practicality, we formalize and verify a previously proposed transformation that hardens C programs against spatial memory safety violations. Vellvm's tools allow us to extract a new, verified implementation of the transformation pass that plugs into the real LLVM infrastructure; its performance is competitive with the non-verified, ad-hoc original."
},
{
  "Title": "Self-Certification: Bootstrapping Certified Typecheckers in F* with Coq",
  "Type": "Paper",
  "Key": "popl211",
  "Authors": ["Pierre-Yves Strub", "Nikhil Swamy", "Cedric Fournet", "Juan Chen"],
  "Affiliations": ["MSR-INRIA", "Microsoft Research"],
  "Abstract": "Well-established dependently-typed languages like Agda and Coq provide reliable ways to build and check formal proofs. Several other dependently-typed languages such as Aura, ATS, Cayenne, Epigram, F*, F7, Fine, Guru, PCML5, and Ur also explore reliable ways to develop and verify programs. All these languages shine in their own regard, but their implementations do not themselves enjoy the degree of safety provided by machine-checked verification. \n\nWe propose a general technique called self-certification that allows a typechecker for a suitably expressive language to be certified for correctness. We have implemented this technique for F*, a dependently typed language on the .NET platform. Self-certification involves implementing a typechecker for F* in F*, while using all the conveniences F* provides for the compiler-writer (e.g., partiality, effects, implicit conversions, proof automation, libraries). This typechecker is given a specification (in~F*) strong enough to ensure that it computes valid typing derivations. We obtain a typing derivation for the core typechecker by running it on itself, and we export it to Coq as a type-derivation certificate. By typechecking this derivation (in Coq) and applying the F* metatheory (also mechanized in Coq), we conclude that our type checker is correct. Once certified in this manner, the F* typechecker is emancipated from Coq. \n\nSelf-certification leads to an efficient certification scheme---we no longer depend on verifying certificates in Coq---as well as a more broadly applicable one. For instance, the self-certified F* checker is suitable for use in adversarial settings where Coq is not intended for use, such as run-time certification of mobile code."
},
{
  "Title": "Verification of Parameterized Concurrent Programs By Modular Reasoning about Data and Control",
  "Type": "Paper",
  "Key": "popl220",
  "Authors": ["Azadeh Farzan", "Zachary Kincaid"],
  "Affiliations": ["University of Toronto"],
  "Abstract": "In this paper, we consider the problem of verifying thread-state properties of multithreaded programs in which the number of active threads cannot be statically bounded. Our approach is based on decomposing the task into two modules, where one reasons about data and the other reasons about control. The data module computes thread-state invariants (e.g., linear constraints over global variables and local variables of one thread) using the thread interference information computed by the control module. The control module computes a representation of thread interference, as an incrementally constructed data flow graph, using the data invariants provided by the data module. These invariants are used to rule out patterns of thread interference that can not occur in a real program execution. The two modules are incorporated into a feedback loop, so that the abstractions of data and interference are iteratively coarsened as the algorithm progresses (that is, they become weaker) until a fixed point is reached. Our approach is sound and terminating, and applicable to programs with infinite state (e.g., unbounded integers) and unboundedly many threads. The verification method presented in this paper has been implemented into a tool, called Duet. We demonstrate the effectiveness of our technique by verifying properties of a selection of Linux device drivers using Duet, and also compare Duet with previous work on verification of parameterized Boolean program using the Boolean abstractions of these drivers."
},
{
  "Title": "Probabilistic Relational Reasoning for Differential Privacy",
  "Type": "Paper",
  "Key": "popl227",
  "Authors": ["Gilles Barthe", "Boris Köpf", "Federico Olmedo", "Santiago Zanella Beguelin"],
  "Affiliations": ["IMDEA Software Institute"],
  "Abstract": "Differential privacy is a notion of confidentiality that protects the privacy of individuals while allowing useful computations on their private data. Deriving differential privacy guarantees for real programs is a difficult and error-prone task that calls for principled approaches and tool support. Approaches based on linear types and static analysis have recently emerged; however, an increasing number of programs achieve privacy using techniques that cannot be analyzed by these approaches. Examples include programs that aim for weaker, approximate differential privacy guarantees, programs that use the Exponential mechanism, and randomized programs that achieve differential privacy without using any standard mechanism. Providing support for reasoning about the privacy of such programs has been an open problem. \n\nWe report on CertiPriv, a machine-checked framework for reasoning about differential privacy built on top of the Coq proof assistant. The central component of CertiPriv is a quantitative extension of a probabilistic relational Hoare logic that enables one to derive differential privacy guarantees for programs from first principles. We demonstrate the expressiveness of CertiPriv using a number of examples whose formal analysis is out of the reach of previous techniques. In particular, we provide the first machine-checked proofs of correctness of the Laplacian and Exponential mechanisms and of the privacy of randomized and streaming algorithms from the recent literature."
},
{
  "Title": "Playing in the Grey Area of Proofs",
  "Type": "Paper",
  "Key": "popl228",
  "Authors": ["Krystof Hoder", "Laura Kovacs", "Andrei Voronkov"],
  "Affiliations": ["University of Manchester", "TU Vienna"],
  "Abstract": "Interpolation is an important technique in verification and static analysis of programs. In particular, interpolants extracted from proofs of various properties are used in invariant generation and bounded model checking. A number of recent papers studies interpolation in various theories and also extraction of smaller interpolants from proofs. In particular, there are several algorithms for extracting of interpolants from so-called local proofs. The main contribution of this paper is a technique of minimising interpolants based on transformations of what we call the 'grey area' of local proofs. Another contribution is a technique of transforming, under certain common conditions, arbitrary proofs into local ones. \n\nUnlike many other interpolation techniques, our technique is very general and applies to arbitrary theories. Our approach is implemented in the theorem prover Vampire and evaluated on a large number of benchmarks coming from first-order theorem proving and bounded model checking using logic with equality, uninterpreted functions and linear integer arithmetic. Our experiments demonstrate the power of the new techniques. for example, it is not unusual that our proof transformation gives more than a tenfold reduction in the size of interpolants."
},
{
  "Title": "Syntactic Control of Interference for Separation Logic",
  "Type": "Paper",
  "Key": "popl233",
  "Authors": ["Uday Reddy", "John Reynolds"],
  "Affiliations": ["University of Birmingham", "Carnegie-Mellon University"],
  "Abstract": "Separation Logic has witnessed tremendous success in recent years in reasoning about programs that deal with heap storage. Its success owes to the fundamental principle that one should keep separate areas of the heap storage separate in program reasoning. However, the way Separation Logic deals with program variables continues to be based on traditional Hoare Logic without taking any benefit of the separation principle. This has led to unwieldy proof rules suffering from lack of clarity as well as questions surrounding their soundness. In this paper, we extend the separation idea to the treatment of variables in Separation Logic, especially Concurrent Separation Logic, using the system of Syntactic Control of Interference proposed by Reynolds in 1978. We extend the original system with permission algebras, making it more powerful and able to deal with the issues of concurrent programs. The result is a streamined presentation of Concurrent Separation Logic, whose rules are memorable and soundness obvious. We also include a discussion of how the new rules impact the semantics and devise static analysis techniques to infer the required permissions automatically."
},
{
  "Title": "Programming Languages for Programmable Networks",
  "Type": "Paper",
  "Key": "popl2jr",
  "Authors": ["Jennifer Rexford"],
  "Affiliations": ["Princeton University"],
  "Abstract": "Today's computer networks perform a bewildering array of tasks, from routing and access control, to traffic monitoring and load balancing. To support wireless users accessing services hosted in the cloud, enterprise and data-center networks are under increasing pressure to support client mobility, virtual-machine migration, resource isolation between cloud services, and energy-efficient operation. Yet, network administrators must configure the network through closed and proprietary interfaces to heterogeneous devices, such as routers, switches, firewalls, load balancers, network address translators, and intrusion detection systems. Not surprisingly, configuring these complex networks is expensive and error-prone, and innovation in network management proceeds at a snail's pace. \n\nDuring the past several years, the networking industry and research community have pushed for greater openness in networking software, and a clearer separation between networking devices and the software that controls them. This broad trend is known as Software Defined Networking (SDN). A hallmark of SDN is having an open interface for controller software running on a commodity computer to install packet-processing rules in the underlying switches. In particular, the OpenFlow protocol (see www.openflow.org) has significant momentum. Many commercial switches support OpenFlow, and a number of campus, data-center, and backbone networks have deployed the new technology. \n\nWith the emergence of open interfaces to network devices, the time is ripe to rethink the design of network software, to put networking on a stronger foundation and foster innovation in networked services. The programming languages community can play a vital role in this transformation, by creating languages, compilers, run-time systems, and testing and verification techniques that raise the level of abstraction for programming the network. In this talk, we give an overview of Software Defined Networking, and survey the early programming-languages research in this area. We also outline exciting opportunities for interdisciplinary research at the intersection of programming languages and computer networks."
},
{
  "Title": "Meta-Level Features in an Industrial-Strength Theorem Prover",
  "Type": "Paper",
  "Key": "popl3sm",
  "Authors": ["J Strother Moore"],
  "Affiliations": ["University of Texas at Austin"],
  "Abstract": "The ACL2 theorem prover---the current incarnation of 'the' Boyer-Moore theorem prover---is a theorem prover for an extension of a first-order, applicative subset of Common Lisp. The ACL2 system provides a useful specification and modeling language as well as a useful mechanical theorem proving environment. ACL2 is in use at several major microprocessor manufacturers to verify functional correctness of important components of commercial designs. This talk explores the design of ACL2 and the tradeoffs that have turned out to be pivotal to its success."
},
{
  "Title": "Presentation of the SIGPLAN Distinguished Achievement Award to Sir Charles Antony Richard Hoare, FRS, FREng, FBCS; and Interview",
  "Type": "Paper",
  "Key": "popl4po",
  "Authors": ["Tony Hoare"],
  "Affiliations": ["Portland State University", "Queen Mary University of London"]
},
{
  "Title": "Exact Type Parameterization and ThisType Support",
  "Type": "Paper",
  "Key": "tldi02",
  "Authors": ["Hyunik Na", "Sukyoung Ryu", "Kwangmoo Choe"],
  "Affiliations": ["KAIST"],
  "Abstract": "We propose language support for binary methods and generic factory methods using ThisType. We present three new language features. (1) exact type capture which relaxes the restriction of earlier static approaches to binary methods that the run-time type of a binary method's receiver should be statically fixed, (2) named wildcards which allow more binary method invocations and more precise typing results, and (3) virtual constructors which support method definitions with return types of ThisType. We formalize these features with a core calculus CoreThisJava and prove its type soundness, exact type match and algorithmic subtyping. A modified notion of ThisType and exact type parameterization with bidirectional F-bound property form the basis of the above features. We also show that 'inheritance makes subtypes' with our notion of ThisType and existential types as object types."
},
{
  "Title": "Static Lock Capabilities for Deadlock Freedom",
  "Type": "Paper",
  "Key": "tldi03",
  "Authors": ["Colin Gordon", "Michael Ernst", "Dan Grossman"],
  "Affiliations": ["University of Washington"],
  "Abstract": "We present a technique --- lock capabilities --- for statically verifying that multithreaded programs with locks will not deadlock. Most previous work on deadlock prevention requires a strict total order on all locks held simultaneously by a thread, but such an invariant often does not hold with fine-grained locking, especially when data-structure mutations change the order locks are acquired. Lock capabilities support idioms that use fine-grained locking, such as mutable binary trees, circular lists, and arrays where each element has a different lock. \n\nLock capabilities do not enforce a total order and do not prevent external references to data-structure nodes. Instead, the technique reasons about static capabilities, where a thread already holding locks can attempt to acquire another lock only if its capabilities allow it. Acquiring one lock may grant a capability to acquire further locks; in data-structures where heap shape affects safe locking orders, the heap structure can induce the capability-granting relation. Deadlock-freedom follows from ensuring that the capability-granting relation is acyclic. Where necessary, we restrict aliasing with a variant of unique references to allow strong updates to the capability-granting relation, while still allowing other aliases that are used only to acquire locks while holding no locks. \n\nWe formalize our technique as a type-and-effect system, demonstrate it handles realistic challenging idioms, and use syntactic techniques (type preservation) to show it soundly prevents deadlock."
},
{
  "Title": "Type Systems for Dummies",
  "Type": "Paper",
  "Key": "tldi05",
  "Authors": ["Andrea Asperti", "Ferruccio Guidi"],
  "Affiliations": ["University of Bologna"],
  "Abstract": "We extend Pure Type Systems with a function turning each term M of type A into a dummy |M| of the same type (|...| is not an identity, in that M != |M|). Intuitively, a dummy represents an unknown, canonical object of the given type. dummies are opaque (cannot be internally inspected), and irrelevant in the sense that dummies of a same type are convertible to each other. This latter condition makes convertibility in PTS with dummies (DPTS) stronger than usual, hence raising not trivial consistency issues. DPTS offer an alternative approach to (proof) irrelevance, tagging irrelevant information at the level of terms and not of types, and avoiding the annoying syntactical duplication of products, abstractions and applications into an explicit and an implicit version, typical of systems like ICC*."
},
{
  "Title": "Giving Haskell a Promotion",
  "Type": "Paper",
  "Key": "tldi08",
  "Authors": ["Brent Yorgey", "Stephanie Weirich", "Julien Cretin", "Simon Peyton Jones", "Dimitrios Vytiniotis", "José Magalhães"],
  "Affiliations": ["University of Pennsylvania", "INRIA", "Microsoft Research", "Utrecht University"],
  "Abstract": "Static type systems strive to be richly expressive while still being simple enough for programmers to use. We describe an experiment that enriches Haskell's kind system with two features promoted from its type system. data types and polymorphism. The new system has a very good power-to-weight ratio. it offers a significant improvement in expressiveness, but, by re-using concepts that programmers are already familiar with, the system is easy to under- stand and implement."
},
{
  "Title": "Types for Relaxed Memory Models",
  "Type": "Paper",
  "Key": "tldi09",
  "Authors": ["Matthew Goto", "Radha Jagadeesan", "Corin Ptcher", "James Riely"],
  "Affiliations": ["DePaul University"],
  "Abstract": "Multicore computers implementing weak memory models are mainstream, yet type-based analyses of these models remain rare. We help fill this gap. We not only prove the soundness of a type system for a weak execution model, but we also show that interesting properties of that model can be embedded in the types themselves. \n\nWe argue that correspondence assertions can be used in a programming discipline that captures happens-before relationships, which are the basis for reasoning about weak memory in Java. This programming discipline is flexible and can be statically enforced. We present several examples from java.util.concurrent and prove the static semantics sound with respect to an execution model based on Java's memory model."
},
{
  "Title": "Towards a Formal Semantics for a Structurally Dynamic Noncausal Modelling Language",
  "Type": "Paper",
  "Key": "tldi10",
  "Authors": ["John Capper", "Henrik Nilsson"],
  "Affiliations": ["University of Nottingham"],
  "Abstract": "Modelling and simulation languages are evolving rapidly to support modelling of systems of ever increasing size and complexity. A relatively recent development in the area of physical modelling is the noncausal modelling languages. They support a declarative, highly modular modelling approach, promoting the reuse of components. Modelica is a prime example of this class of languages. However, the mainstream representatives of this class of languages provide limited support for higher-order modelling and structurally dynamic systems. Moreover, the semantics of this class of languages remains a relatively unexplored area. Functional Hybrid Modelling (FHM) is a novel approach to noncausal, hybrid modelling that aims to address these concerns. In this paper, we give a semantics to the discrete part of a simple FHM language expressed in dependent type theory. We use Normalisation by Evaluation to produce a type-preserving and terminating normalisation procedure, the latter property being particularly important for FHM as highly structurally dynamic systems are supported by computing new system configurations during simulation. Furthermore, our implementation has been carefully structured to allow continuous aspects of the semantics to be described separately, in whatever way is deemed appropriate, while retaining the ability to describe precisely how a system evolves in response to discrete events."
},
{
  "Title": "Row-based Effect Types for Database Integration",
  "Type": "Paper",
  "Key": "tldi12",
  "Authors": ["Sam Lindley", "James Cheney"],
  "Affiliations": ["The University of Edinburgh"],
  "Abstract": "We present CoreLinks, a call-by-value variant of System F with row polymorphism, row-based effect types, and implicit subkinding, which forms the basis for the Links web programming language. We focus on extensions to CoreLinks for database programming. The effect types support abstraction over database queries, while ensuring that queries are translated predictably to idiomatic and efficient SQL at run-time. Subkinding statically enforces the constraint that queries must return a list of records of base type. Polymorphism over the presence of record labels supports abstraction over database queries, inserts, deletes and updates."
},
{
  "Title": "Semantics for Graphical User Interfaces",
  "Type": "Paper",
  "Key": "tldi15n",
  "Authors": ["Neelakantan Krishnaswami"],
  "Affiliations": ["Max Planck Institute for Software Systems"],
  "Abstract": "Graphical user interface (GUI) libraries are one of the most widely-encountered higher-order interfaces. Even in languages (such as Java and C++) where programmers customarily avoid higher-order abstractions, the GUI toolkit interface is invariably higher-order. \n\n The foundation of these libraries is the callback. the display is conceptualized as something evolving over time, and programs register their interest in the changes the display undergoes by passing it functions to invoke whenever a given change happens. Alas, programs making heavy use of callbacks are notoriously dificult to write. they are all three of imperative, concurrent, and higher-order. There are design patterns (such as the model-view-controller pattern) for writing such programs, but verification (and even specification!) of interactive programs written in this style remains very difficult. \n\n One attractive approach for taming this complexity has been functional reactive programming. This model eliminates imperative state from the semantic model of interactive programs by treating time-varying values as first-class datatype, and eliminates concurrency by taking a synchronous view of time, thereby leaving us on the familiar ground of purely functional programming. \n\n Unfortunately, direct implementations of functional reactive programming tend to suffer from poor efficiency, arising from the mismatch between the mathematical abstraction of a stream and their realization in terms of mutable state. The typical response has been to follow the example of synchronous dataflow languages, and restrict the definable abstractions. \n\n This talk surveys a recent line of work which fully supports the functional style (including full support for higher-order functions and higher-type streams), whilst still permitting efficient implementation. This work draws on a wide array of work ranging from metric-space approaches to denotational semantics, step-indexing, modal logic, to linear logic. \n\n In the talk, we will also illustrate functional GUI programming with a series of examples in AdjS, a new programming language based on this model."
},
{
  "Title": "Towards Concurrent Type Theory",
  "Type": "Paper",
  "Key": "tldi17f",
  "Authors": ["Luís Caires", "Frank Pfenning", "Bernardo Toninho"],
  "Affiliations": ["Universidade Nova de Lisboa", "Carnegie Mellon University", "Carnegie Mellon University & Universidade Nove de Lisboa"],
  "Abstract": "We review progress in a recent line of research that provides a concurrent computational interpretation of (intuitionistic) linear logic. Propositions are interpreted as session types, sequent proofs as processes in the pi-calculus, cut reductions as process reductions, and vice versa. The strong proof-theoretic foundation of this type system provides immediate opportunities for uniform generalization, specifically, to embed terms from a functional type theory. The resulting system satisfies the properties of type preservation, progress, and termination, as expected from a language derived via a Curry-Howard isomorphism. While very expressive, the language is strictly stratified so that dependent types for functional terms can be enforced during communication, but neither processes nor channels can appear in functional terms. We briefly speculate on how this limitation might be overcome to arrive at a fully dependent concurrent type theory."
}
	],
	"Sessions": [
{
  "Title": "Verification",
  "ShortTitle": "Verification",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "Verification",
  "Day": "1/25/2012",
  "Time": "11:00 am - 12:30 pm",
  "Location": "Ballroom CDE",
  "Items": ["popl127", "popl148", "popl190"],
  "Chair": "Ranjit Jhala"
},
{
  "Title": "Semantics",
  "ShortTitle": "Semantics",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "Semantics",
  "Day": "1/25/2012",
  "Time": "11:00 am - 12:30 pm",
  "Location": "Ballroom AB",
  "Items": ["popl044", "popl074", "popl087"],
  "Chair": "Patricia Johann"
},
{
  "Title": "Privacy and Access Control",
  "ShortTitle": "Privacy and Access Control",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "PrivacyandAccessControl",
  "Day": "1/25/2012",
  "Time": "2:00 pm - 3:30 pm",
  "Location": "Ballroom CDE",
  "Items": ["popl088", "popl121", "popl227"],
  "Chair": "Nikhil Swamy"
},
{
  "Title": "Decision Procedures",
  "ShortTitle": "Decision Procedures",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "DecisionProcedures",
  "Day": "1/25/2012",
  "Time": "2:00 pm - 3:30 pm",
  "Location": "Ballroom AB",
  "Items": ["popl052", "popl150", "popl171"],
  "Chair": "Swarat Chauduri"
},
{
  "Title": "Security",
  "ShortTitle": "Security",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "Security",
  "Day": "1/25/2012",
  "Time": "4:15 pm - 5:15 pm",
  "Location": "Ballroom CDE",
  "Items": ["popl002", "popl041"],
  "Chair": "Neelakantan Krishnaswami"
},
{
  "Title": "Complexity for Concurrency",
  "ShortTitle": "Complexity for Concurrency",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "ComplexityforConcurrency",
  "Day": "1/25/2012",
  "Time": "4:15 pm - 5:15 pm",
  "Location": "Ballroom AB",
  "Items": ["popl115", "popl192"],
  "Chair": "Madhusudan Parthasarathy"
},
{
  "Title": "Medley",
  "ShortTitle": "Medley",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "Medley",
  "Day": "1/26/2012",
  "Time": "11:00 am - 12:30 pm",
  "Location": "Ballroom CDE",
  "Items": ["popl061", "popl086", "popl194"],
  "Chair": "Suresh Jagannathan"
},
{
  "Title": "Mechanized Proofs",
  "ShortTitle": "Mechanized Proofs",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "MechanizedProofs",
  "Day": "1/26/2012",
  "Time": "11:00 am - 12:30 pm",
  "Location": "Ballroom AB",
  "Items": ["popl089", "popl180", "popl228"],
  "Chair": "Adam Chlipala"
},
{
  "Title": "Concurrency",
  "ShortTitle": "Concurrency",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "Concurrency",
  "Day": "1/26/2012",
  "Time": "2:00 pm - 3:30 pm",
  "Location": "Ballroom CDE",
  "Items": ["popl147", "popl220", "popl233"],
  "Chair": "Matthew Parkinson"
},
{
  "Title": "Type Theory",
  "ShortTitle": "Type Theory",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "TypeTheory",
  "Day": "1/26/2012",
  "Time": "2:00 pm - 3:30 pm",
  "Location": "Ballroom AB",
  "Items": ["popl062", "popl124", "popl182"],
  "Chair": "Stephanie Weirich"
},
{
  "Title": "Dynamic Analysis",
  "ShortTitle": "Dynamic Analysis",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "DynamicAnalysis",
  "Day": "1/26/2012",
  "Time": "4:15 pm - 5:15 pm",
  "Location": "Ballroom CDE",
  "Items": ["popl103", "popl167"],
  "Chair": "Aarti Gupta"
},
{
  "Title": "Names and Binders",
  "ShortTitle": "Names and Binders",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "NamesandBinders",
  "Day": "1/26/2012",
  "Time": "4:15 pm - 5:15 pm",
  "Location": "Ballroom AB",
  "Items": ["popl112", "popl133"],
  "Chair": "Zhong Shao"
},
{
  "Title": "Verified Transformations",
  "ShortTitle": "Verified Transformations",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "VerifiedTransformations",
  "Day": "1/27/2012",
  "Time": "11:00 am - 12:30 pm",
  "Location": "Ballroom CDE",
  "Items": ["popl075", "popl093", "popl208"],
  "Chair": "Chris Hawblitzel"
},
{
  "Title": "Functional Programming",
  "ShortTitle": "Functional Programming",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "FunctionalProgramming",
  "Day": "1/27/2012",
  "Time": "11:00 am - 12:30 pm",
  "Location": "Ballroom AB",
  "Items": ["popl018", "popl153", "popl195"],
  "Chair": "Dimitrios Vytiniotis"
},
{
  "Title": "C/C++ Semantics",
  "ShortTitle": "C/C++ Semantics",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "CCSemantics",
  "Day": "1/27/2012",
  "Time": "2:00 pm - 3:30 pm",
  "Location": "Ballroom CDE",
  "Items": ["popl027", "popl079", "popl106"],
  "Chair": "Andreas Podelski"
},
{
  "Title": "Type Systems",
  "ShortTitle": "Type Systems",
  "Type": "Technical Papers",
  "ShortType": "Technical Papers",
  "Key": "TypeSystems",
  "Day": "1/27/2012",
  "Time": "2:00 pm - 3:30 pm",
  "Location": "Ballroom AB",
  "Items": ["popl098", "popl201", "popl211"],
  "Chair": "Norman Ramsey"
},
{
  "Title": "Breakfast",
  "ShortTitle": "Breakfast",
  "Type": "Meal",
  "ShortType": "Meal",
  "Key": "Breakfast",
  "Day": "1/25/2012",
  "Time": "8:30 am - 9:20 am"
},
{
  "Title": "Welcome",
  "ShortTitle": "Welcome",
  "Type": "Announcements",
  "ShortType": "Announcements",
  "Key": "Welcome",
  "Day": "1/25/2012",
  "Time": "9:20 am - 9:30 am"
},
{
  "Title": "ACM SIGPLAN Programming Languages Achievement Award Interview",
  "ShortTitle": "SIGPLAN Award Interview",
  "Type": "Invited Talk",
  "ShortType": "Invited Talk",
  "Key": "ACMSIGPLANProgrammingLanguagesAchievementAwardInterview",
  "Day": "1/25/2012",
  "Time": "9:30 am - 10:30 am",
  "Items": ["popl4po"],
  "Chairs": ["Andrew Black", "Peter O'Hearn"]
},
{
  "Title": "Student Session",
  "ShortTitle": "Student Session",
  "Type": "Student Session",
  "ShortType": "Student Session",
  "Key": "StudentSession",
  "Day": "1/25/2012",
  "Time": "6:00 pm - 8:00 pm",
  "Chair": "Tobias Wrigstad"
},
{
  "Title": "Breakfast",
  "ShortTitle": "Breakfast",
  "Type": "Meal",
  "ShortType": "Meal",
  "Key": "Breakfast-1",
  "Day": "1/26/2012",
  "Time": "8:30 am - 9:20 am"
},
{
  "Title": "General Announcements",
  "ShortTitle": "Announcements",
  "Type": "Announcements",
  "ShortType": "Announcements",
  "Key": "GeneralAnnouncements",
  "Day": "1/26/2012",
  "Time": "9:20 am - 9:30 am"
},
{
  "Title": "Programming Languages for Programmable Networks",
  "ShortTitle": "Programmable Networks",
  "Type": "Invited Talk",
  "ShortType": "Invited Talk",
  "Key": "ProgrammingLanguagesforProgrammableNetworks",
  "Day": "1/26/2012",
  "Time": "9:30 am - 10:30 am",
  "Items": ["popl2jr"],
  "Chair": "Michael Hicks"
},
{
  "Title": "Business Meeting",
  "ShortTitle": "Business Meeting",
  "Type": "Business Meeting",
  "ShortType": "Business Meeting",
  "Key": "BusinessMeeting",
  "Day": "1/26/2012",
  "Time": "5:15 pm - 5:45 pm"
},
{
  "Title": "Banquet",
  "ShortTitle": "Banquet",
  "Type": "Meal",
  "ShortType": "Meal",
  "Key": "Banquet",
  "Day": "1/26/2012",
  "Time": "6:30 pm - 10:00 pm"
},
{
  "Title": "Breakfast",
  "ShortTitle": "Breakfast",
  "Type": "Meal",
  "ShortType": "Meal",
  "Key": "Breakfast-2",
  "Day": "1/27/2012",
  "Time": "8:30 am - 9:20 am"
},
{
  "Title": "Popl '13 Preview",
  "ShortTitle": "Popl '13 Preview",
  "Type": "Announcements",
  "ShortType": "Announcements",
  "Key": "Popl13Preview",
  "Day": "1/27/2012",
  "Time": "9:20 am - 9:30 am"
},
{
  "Title": "Meta-Level Features in an Industrial Strength Theorem Prover",
  "ShortTitle": "Meta-Level Features",
  "Type": "Invited Talk",
  "ShortType": "Invited Talk",
  "Key": "MetaLevelFeaturesinanIndustrialStrengthTheoremProver",
  "Day": "1/27/2012",
  "Time": "9:30 am - 10:30 am",
  "Items": ["popl3sm"],
  "Chair": "John Field"
},
{
  "Title": "Closing & Raffle",
  "ShortTitle": "Closing & Raffle",
  "Type": "Announcements",
  "ShortType": "Announcements",
  "Key": "ClosingRaffle",
  "Day": "1/27/2012",
  "Time": "3:30 pm - 4:00 pm"
},
{
  "Title": "Declarative Aspects and Applications of Multicore Programming",
  "ShortTitle": "DAMP 2012",
  "Type": "Workshop",
  "ShortType": "Workshop",
  "Key": "DeclarativeAspectsandApplicationsofMulticoreProgramming",
  "Day": "1/28/2012",
  "Time": "9:00 am - 6:10 pm",
  "Location": "Ballroom A2",
  "Abstract": "The advent of multicore architectures has profoundly increased the importance of research in parallel computing. Multicore architectures, now commonplace, introduce several new dimensions of variability in both performance guarantees and architectural contracts, such as the memory model, while making it highly attractive and even necessary to develop novel programming languages, models, and paradigms for taking advantage of the benefits of parallelism. Programs written in declarative languages, which control the use of side effects, can greatly simplify development of parallel programs by eliminating or limiting data races. Such languages include purely functional languages, (constraint-) logic programming languages, many data-driven or reactive languages, and other domain specific languages (e.g., MapReduce). ",
  "Workshop": true,
  "Items": ["damp1", "damp2", "damp3", "damp4", "damp5s", "damp7s", "damp9s"]
},
{
  "Title": "Partial Evaluation and Program Manipulation",
  "ShortTitle": "PEPM 2012",
  "Type": "Workshop",
  "ShortType": "Workshop",
  "Key": "PartialEvaluationandProgramManipulation",
  "Day": "1/23/2012",
  "Time": "8:50 am - 5:00 pm",
  "Location": "Ballroom E",
  "Abstract": "The PEPM Symposium/Workshop series aims to bring together researchers and practitioners working in the broad area of program transformation, which spans from refactoring, partial evaluation, supercompilation, fusion and other metaprogramming to model-driven development, program analyses including termination, inductive programming, program generation and applications of machine learning and probabilistic search. PEPM focuses on techniques, supporting theory, tools, and applications of the analysis and manipulation of programs. Each technique or tool of program manipulation should have a clear, although perhaps informal, statement of desired properties, along with an argument how these properties could be achieved. ",
  "Workshop": true,
  "Items": ["pepm01", "pepm02", "pepm03", "pepm04", "pepm05", "pepm06", "pepm07", "pepm08", "pepm09", "pepm10b", "pepm11", "pepm12", "pepm13", "pepm14b", "pepm1pm", "pepm21s", "pepm22s", "pepm2mb", "pepm31t", "pepm32t", "pepm33t"]
},
{
  "Title": "Programming Languages meets Program Verification",
  "ShortTitle": "PLPV 2012",
  "Type": "Workshop",
  "ShortType": "Workshop",
  "Key": "ProgrammingLanguagesmeetsProgramVerification",
  "Day": "1/24/2012",
  "Time": "9:00 am - 5:00 pm",
  "Location": "Ballroom D",
  "Abstract": "The goal of PLPV is to foster and stimulate research at the intersection of programming languages and program verification, by bringing together experts from diverse areas like types, contracts, interactive theorem proving, model checking and program analysis. Work in this area typically attempts to reduce the burden of program verification by taking advantage of particular semantic or structural properties of the programming language. Examples include dependently typed programming languages, which leverage a language's type system to specify and check richer than usual specifications or extended static checking systems which incorporate contracts with either static or dynamic contract checking. ",
  "Workshop": true,
  "Items": ["plpv01", "plpv03", "plpv05", "plpv08", "plpv10", "plpv12", "plpv13", "plpv21v"]
},
{
  "Title": "Types in Language Design and Implementation",
  "ShortTitle": "TLDI 2012",
  "Type": "Workshop",
  "ShortType": "Workshop",
  "Key": "TypesinLanguageDesignandImplementation",
  "Day": "1/28/2012",
  "Time": "9:00 am - 5:20 pm",
  "Location": "Ballroom B",
  "Abstract": "The role of types and proofs in all aspects of language design, compiler construction, and software development has expanded greatly in recent years. Type systems, type analyses, and formal deduction have led to new concepts in compilation techniques for modern programming languages, verification of safety and security properties of programs, program transformation and optimization, and many other areas. In light of this expanding role of types, the Seventh ACM SIGPLAN Workshop on Types in Language Design and Implementation (TLDI 2012) aims to bring together researchers from around the globe to share exciting new ideas and results in this area. This year's workshop is the tenth in a series of international workshops, originating in 1997 as the Workshop on Types in Compilation (TIC). ",
  "Workshop": true,
  "Items": ["tldi02", "tldi03", "tldi05", "tldi08", "tldi09", "tldi10", "tldi12", "tldi15n", "tldi17f"]
}
	],
	"People": [
{
    "Name": "Aaron Stump",
    "Affiliation": "University of Iowa"
},
{
    "Name": "Abdorreza Savadi",
    "Affiliation": "Ferdowsi University of Mashhad (FUM)"
},
{
    "Name": "Adriaan Moors",
    "Affiliation": "EPFL"
},
{
    "Name": "Afshin Amighi",
    "Affiliation": "University of Twente"
},
{
    "Name": "Ahmed Bouajjani",
    "Affiliation": "Université Paris Diderot"
},
{
    "Name": "Akash Lal",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Alan Jeffrey",
    "Affiliation": "Alcatel-Lucent"
},
{
    "Name": "Alex Shafarenko",
    "Affiliation": "University of Hertfordshire"
},
{
    "Name": "Alexander Gray",
    "Affiliation": "Georgia Institute of Technology"
},
{
    "Name": "Ali Sinan Köksal",
    "Affiliation": "Swiss Federal Institute of Technology (EPFL)"
},
{
    "Name": "Amr Sabry",
    "Affiliation": "Indiana University"
},
{
    "Name": "Andrea Asperti",
    "Affiliation": "University of Bologna"
},
{
    "Name": "Andrei Stefanescu",
    "Affiliation": "University of Illinois at Urbana-Champaign"
},
{
    "Name": "Andrei Voronkov",
    "Affiliation": "University of Manchester"
},
{
    "Name": "Andrew Black",
    "Affiliation": "Portland State University"
},
{
    "Name": "Andrew Cave",
    "Affiliation": "McGill University"
},
{
    "Name": "Annette Bieniusa",
    "Affiliation": "INRIA Paris-Rocquencourt and LIP6"
},
{
    "Name": "Antonis Stampoulis",
    "Affiliation": "Yale University"
},
{
    "Name": "Armando Solar-Lezama",
    "Affiliation": "Massachusetts Institute of Technology"
},
{
    "Name": "Arvind Sujeeth",
    "Affiliation": "Stanford"
},
{
    "Name": "Aseem Rastogi",
    "Affiliation": "Stony Brook University"
},
{
    "Name": "Ashish Agarwal",
    "Affiliation": "New York University"
},
{
    "Name": "Avik Chaudhuri",
    "Affiliation": "Adobe Systems"
},
{
    "Name": "Ayumi Shinohara",
    "Affiliation": "Tohoku University"
},
{
    "Name": "Azadeh Farzan",
    "Affiliation": "University of Toronto"
},
{
    "Name": "Bartek Klin",
    "Affiliation": "University of Warsaw"
},
{
    "Name": "Basil Hosmer",
    "Affiliation": "Adobe Systems"
},
{
    "Name": "Benjamin Livshits",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Benjamin Pierce",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "Bernardo Toninho",
    "Affiliation": "Carnegie Mellon University & Universidade Nove de Lisboa"
},
{
    "Name": "Bernhard Scholz",
    "Affiliation": "The University of Sydney"
},
{
    "Name": "Bertrand Meyer",
    "Affiliation": "ETH Zurich"
},
{
    "Name": "Bjarte Østvold",
    "Affiliation": "Norwegian Computing Center"
},
{
    "Name": "Bo Svensson",
    "Affiliation": "Chalmers University of Technology"
},
{
    "Name": "Boris Köpf",
    "Affiliation": "IMDEA Software Institute"
},
{
    "Name": "Brent Yorgey",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "Brigitte Pientka",
    "Affiliation": "McGill University"
},
{
    "Name": "Bugra Gedik",
    "Affiliation": "IBM Watson Research Center"
},
{
    "Name": "Caitlin Sadowski",
    "Affiliation": "University of California, Santa Cruz"
},
{
    "Name": "Carl Eastlund",
    "Affiliation": "Northeastern University & PLT"
},
{
    "Name": "Casey Klein",
    "Affiliation": "Northwestern University & PLT"
},
{
    "Name": "Cedric Fournet",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Chenyi Zhang",
    "Affiliation": "University of Queensland"
},
{
    "Name": "Chris Casinghino",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "Christopher Monsanto",
    "Affiliation": "Princeton University"
},
{
    "Name": "Christos Dimoulas",
    "Affiliation": "Northeastern University & PLT"
},
{
    "Name": "Chucky Ellison",
    "Affiliation": "University of Illinois"
},
{
    "Name": "Chung-Kil Hur",
    "Affiliation": "MPI-SWS"
},
{
    "Name": "Colin Gordon",
    "Affiliation": "University of Washington"
},
{
    "Name": "Corin Ptcher",
    "Affiliation": "DePaul University"
},
{
    "Name": "Cormac Flanagan",
    "Affiliation": "University of California, Santa Cruz"
},
{
    "Name": "Cristiano Calcagno",
    "Affiliation": "Imperial College London"
},
{
    "Name": "Dan Grossman",
    "Affiliation": "University of Washington"
},
{
    "Name": "Dana Xu",
    "Affiliation": "INRIA"
},
{
    "Name": "Daniel Licata",
    "Affiliation": "Carnegie Mellon University"
},
{
    "Name": "Daniel Wagner",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "David Molnar",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "David Nowak",
    "Affiliation": "National Institute of Advanced Industrial Science and Technology"
},
{
    "Name": "David Walker",
    "Affiliation": "Princeton University"
},
{
    "Name": "Derek Dreyer",
    "Affiliation": "MPI-SWS"
},
{
    "Name": "Didier Rémy",
    "Affiliation": "INRIA"
},
{
    "Name": "Dimitrios Vytiniotis",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Dominic Duggan",
    "Affiliation": "Stevens Institute of Technology"
},
{
    "Name": "Donald Ray",
    "Affiliation": "University of South Florida"
},
{
    "Name": "Edvard Karlsen",
    "Affiliation": "Sør-Trøndelag University College"
},
{
    "Name": "Einar Høst",
    "Affiliation": "Computas AS"
},
{
    "Name": "Elvira Albert",
    "Affiliation": "Complutense University of Madrid"
},
{
    "Name": "Enrique Martin-Martin",
    "Affiliation": "Universidad Complutense de Madrid"
},
{
    "Name": "Eva Burrows",
    "Affiliation": "University of Bergen"
},
{
    "Name": "Federico Olmedo",
    "Affiliation": "IMDEA Software Institute"
},
{
    "Name": "Fernando Silva",
    "Affiliation": "CRACS & INESC TEC, Faculty of Sciences, University of Porto"
},
{
    "Name": "Ferruccio Guidi",
    "Affiliation": "University of Bologna"
},
{
    "Name": "Francisco López-Fraguas",
    "Affiliation": "Universidad Complutense de Madrid"
},
{
    "Name": "Frank Penczek",
    "Affiliation": "University of Hertfordshire"
},
{
    "Name": "Frank Pfenning",
    "Affiliation": "Carnegie Mellon University"
},
{
    "Name": "Gabriel Dos Reis",
    "Affiliation": "Texas A&M University"
},
{
    "Name": "Gareth Smith",
    "Affiliation": "Imperial College"
},
{
    "Name": "Garrin Kimmell",
    "Affiliation": "University of Iowa"
},
{
    "Name": "Geoffrey Hamilton",
    "Affiliation": "Dublin City University"
},
{
    "Name": "Georg Neis",
    "Affiliation": "MPI-SWS"
},
{
    "Name": "Germán Puebla",
    "Affiliation": "Technical University of Madrid"
},
{
    "Name": "Ghila Castelnuovo",
    "Affiliation": "Tel-Aviv University"
},
{
    "Name": "Gilles Barthe",
    "Affiliation": "IMDEA Software Institute"
},
{
    "Name": "Gordon Plotkin",
    "Affiliation": "University of Edinburgh"
},
{
    "Name": "Grigore Rosu",
    "Affiliation": "University of Illinois"
},
{
    "Name": "Guillermo Román-Díez",
    "Affiliation": "Technical University of Madrid"
},
{
    "Name": "Harley Eades",
    "Affiliation": "University of Iowa"
},
{
    "Name": "Hassan Chafi",
    "Affiliation": "Stanford"
},
{
    "Name": "Henrik Nilsson",
    "Affiliation": "University of Nottingham"
},
{
    "Name": "Hongjin Liang",
    "Affiliation": "University of Science and Technology of China"
},
{
    "Name": "Hongseok Yang",
    "Affiliation": "University of Oxford"
},
{
    "Name": "Hossein Deldari",
    "Affiliation": "Islamic Azad University-Mashhad Branch (IAUM)"
},
{
    "Name": "Hyunik Na",
    "Affiliation": "KAIST"
},
{
    "Name": "Isabella Mastroeni",
    "Affiliation": "University of Verona"
},
{
    "Name": "Isao Sasano",
    "Affiliation": "Shibaura Institute of Technology"
},
{
    "Name": "J Moore",
    "Affiliation": "University of Texas at Austin"
},
{
    "Name": "Jacob Evans",
    "Affiliation": "University of Massachusetts"
},
{
    "Name": "Jacques Carette",
    "Affiliation": "McMaster University"
},
{
    "Name": "Jaeheon Yi",
    "Affiliation": "University of California, Santa Cruz"
},
{
    "Name": "James Cheney",
    "Affiliation": "The University of Edinburgh"
},
{
    "Name": "James Riely",
    "Affiliation": "DePaul University"
},
{
    "Name": "Jan Hoffmann",
    "Affiliation": "Yale University"
},
{
    "Name": "Janis Voigtländer",
    "Affiliation": "University of Bonn"
},
{
    "Name": "Jay Ligatti",
    "Affiliation": "University of South Florida"
},
{
    "Name": "Jay McCarthy",
    "Affiliation": "Brigham Young University & PLT"
},
{
    "Name": "Jean Yang",
    "Affiliation": "Massachusetts Institute of Technology"
},
{
    "Name": "Jennifer Rexford",
    "Affiliation": "Princeton University"
},
{
    "Name": "Jesús Correas",
    "Affiliation": "Complutense University of Madrid"
},
{
    "Name": "Jianhua Yao",
    "Affiliation": "Stevens Institute of Technology"
},
{
    "Name": "Jianzhou Zhao",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "John Capper",
    "Affiliation": "University of Nottingham"
},
{
    "Name": "John Clements",
    "Affiliation": "California Polytechnic State University & PLT"
},
{
    "Name": "John Reynolds",
    "Affiliation": "Carnegie-Mellon University"
},
{
    "Name": "Jon Rafkind",
    "Affiliation": "University of Utah & PLT"
},
{
    "Name": "Jonathan Aldrich",
    "Affiliation": "Carnegie Mellon University"
},
{
    "Name": "Jonathan Kelner",
    "Affiliation": "MIT"
},
{
    "Name": "José Magalhães",
    "Affiliation": "Utrecht University"
},
{
    "Name": "Juan Chen",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Juan Rodríguez-Hortalá",
    "Affiliation": "Universidad Complutense de Madrid"
},
{
    "Name": "Julien Cretin",
    "Affiliation": "INRIA"
},
{
    "Name": "Karl Naden",
    "Affiliation": "Carnegie Mellon University"
},
{
    "Name": "Kayvan Memarian",
    "Affiliation": "University of Cambridge & INRIA"
},
{
    "Name": "Kazuhiro Inaba",
    "Affiliation": "National Institute of Informatics"
},
{
    "Name": "Kazutaka Matsuda",
    "Affiliation": "Tohoku University"
},
{
    "Name": "Keisuke Nakano",
    "Affiliation": "The University of Electro-Communications"
},
{
    "Name": "Kevin Bierhoff",
    "Affiliation": "Two Sigma Investments"
},
{
    "Name": "Ki Yung Ahn",
    "Affiliation": "Portland State University"
},
{
    "Name": "Klaus Schneider",
    "Affiliation": "TU Kaiserslautern"
},
{
    "Name": "Koen Claessen",
    "Affiliation": "Chalmers University of Technology"
},
{
    "Name": "Krystof Hoder",
    "Affiliation": "University of Manchester"
},
{
    "Name": "Kuat Yessenov",
    "Affiliation": "Massachusetts Institute of Technology"
},
{
    "Name": "Kwangmoo Choe",
    "Affiliation": "KAIST"
},
{
    "Name": "Laura Kovacs",
    "Affiliation": "TU Vienna"
},
{
    "Name": "Laurent Braud",
    "Affiliation": "University of Warsaw"
},
{
    "Name": "Luís Caires",
    "Affiliation": "Universidade Nova de Lisboa"
},
{
    "Name": "Madhusudan Parthasarathy",
    "Affiliation": "University of Illinois at Urbana-Champaign"
},
{
    "Name": "Magne Haveraaen",
    "Affiliation": "University of Bergen"
},
{
    "Name": "Manuel Gesell",
    "Affiliation": "TU Kaiserslautern"
},
{
    "Name": "Margus Veanes",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Marieke Huisman",
    "Affiliation": "University of Twente"
},
{
    "Name": "Marina Zaharieva-Stojanovski",
    "Affiliation": "University of Twente"
},
{
    "Name": "Mark Batty",
    "Affiliation": "University of Cambridge"
},
{
    "Name": "Markus Degen",
    "Affiliation": "University of Freiburg"
},
{
    "Name": "Markus Püschel",
    "Affiliation": "ETH Zürich"
},
{
    "Name": "Martin Berger",
    "Affiliation": "University of Sussex"
},
{
    "Name": "Martin Hirzel",
    "Affiliation": "IBM Watson Research Center"
},
{
    "Name": "Martin Hofmann",
    "Affiliation": "Ludwig-Maximilians-Universität München"
},
{
    "Name": "Martin Odersky",
    "Affiliation": "EPFL"
},
{
    "Name": "Martin Rinard",
    "Affiliation": "MIT"
},
{
    "Name": "Mary Sheeran",
    "Affiliation": "Chalmers University of Technology"
},
{
    "Name": "Matko Botincan",
    "Affiliation": "University of Cambridge"
},
{
    "Name": "Matthew Flatt",
    "Affiliation": "University of Utah & PLT"
},
{
    "Name": "Matthew Goto",
    "Affiliation": "DePaul University"
},
{
    "Name": "Matthias Felleisen",
    "Affiliation": "Northeastern University & PLT"
},
{
    "Name": "Mayur Naik",
    "Affiliation": "Georgia Institute of Technology"
},
{
    "Name": "Meriem Ouederni",
    "Affiliation": "University of Malaga"
},
{
    "Name": "Michael Emmi",
    "Affiliation": "Université Paris Diderot"
},
{
    "Name": "Michael Ernst",
    "Affiliation": "University of Washington"
},
{
    "Name": "Michael Gorbovitski",
    "Affiliation": "State University of New York at Stony Brook"
},
{
    "Name": "Miguel Gómez-Zamalloa",
    "Affiliation": "Complutense University of Madrid"
},
{
    "Name": "Mike Dodds",
    "Affiliation": "University of Cambridge"
},
{
    "Name": "Mikolaj Bojanczyk",
    "Affiliation": "University of Warsaw"
},
{
    "Name": "Milo Martin",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "Ming Fu",
    "Affiliation": "University of Science and Technology of China"
},
{
    "Name": "Mooly Sagiv",
    "Affiliation": "Tel-Aviv University"
},
{
    "Name": "Morteza Moradi",
    "Affiliation": "Islamic Azad University-Mashhad Branch (IAUM)"
},
{
    "Name": "Naoki Kobayashi",
    "Affiliation": "Tohoku University"
},
{
    "Name": "Nate Foster",
    "Affiliation": "Cornell University"
},
{
    "Name": "Nathan Collins",
    "Affiliation": "Portland State University"
},
{
    "Name": "Neelakantan Krishnaswami",
    "Affiliation": "Max Planck Institute for Software Systems"
},
{
    "Name": "Neil Jones",
    "Affiliation": "University of Copenhagen"
},
{
    "Name": "Nick Benton",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Nikhil Swamy",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Nikolaj Bjorner",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Ohad Kammar",
    "Affiliation": "University of Edinburgh"
},
{
    "Name": "Patrick Cousot",
    "Affiliation": "CNRS, Ecole Normale Superieure, and INRIA, France and Courant Institute, NYU, USA"
},
{
    "Name": "Patrick Rondon",
    "Affiliation": "University of California, San Diego"
},
{
    "Name": "Paul Bone",
    "Affiliation": "The University of Melbourne & National ICT Australia (NICTA)"
},
{
    "Name": "Peng Fu",
    "Affiliation": "University of iowa"
},
{
    "Name": "Peter O'Hearn",
    "Affiliation": "Queen Mary University of London"
},
{
    "Name": "Peter Schachte",
    "Affiliation": "The University of Melbourne"
},
{
    "Name": "Peter Sewell",
    "Affiliation": "University of Cambridge"
},
{
    "Name": "Peter Thiemann",
    "Affiliation": "University of Freiburg"
},
{
    "Name": "Peter-Michael Osera",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "Philipp Haller",
    "Affiliation": "EPFL and Stanford"
},
{
    "Name": "Philippa Gardner",
    "Affiliation": "Imperial College"
},
{
    "Name": "Philippe Suter",
    "Affiliation": "Swiss Federal Institute of Technology (EPFL)"
},
{
    "Name": "Phillip Heidegger",
    "Affiliation": "University of Freiburg"
},
{
    "Name": "Pierre-Yves Strub",
    "Affiliation": "MSR-INRIA"
},
{
    "Name": "Pieter Hooimeijer",
    "Affiliation": "University of Virginia"
},
{
    "Name": "Puri Arenas",
    "Affiliation": "Complutense University of Madrid"
},
{
    "Name": "Radha Jagadeesan",
    "Affiliation": "DePaul University"
},
{
    "Name": "Radhia Cousot",
    "Affiliation": "CNRS, Ecole Normale Superieure, and INRIA, France"
},
{
    "Name": "Raimund Kirner",
    "Affiliation": "University of Hertfordshire"
},
{
    "Name": "Ranjit Jhala",
    "Affiliation": "University of California, San Diego"
},
{
    "Name": "Ravi Chugh",
    "Affiliation": "University of California, San Diego"
},
{
    "Name": "Reynald Affeldt",
    "Affiliation": "National Institute of Advanced Industrial Science and Technology"
},
{
    "Name": "Ricardo Rocha",
    "Affiliation": "CRACS & INESC TEC, Faculty of Sciences, University of Porto"
},
{
    "Name": "Richard Vuduc",
    "Affiliation": "Georgia Institute of Technology"
},
{
    "Name": "Rob Harrison",
    "Affiliation": "United States Military Academy"
},
{
    "Name": "Robert Bocchino",
    "Affiliation": "Carnegie Mellon University"
},
{
    "Name": "Robert Findler",
    "Affiliation": "Northwestern University"
},
{
    "Name": "Robert Harper",
    "Affiliation": "Carnegie Mellon University"
},
{
    "Name": "Roberto Giacobazzi",
    "Affiliation": "University of Verona"
},
{
    "Name": "Roshan James",
    "Affiliation": "Indiana University"
},
{
    "Name": "Rui Vieira",
    "Affiliation": "CRACS & INESC TEC, Faculty of Sciences, University of Porto"
},
{
    "Name": "Sam Lindley",
    "Affiliation": "The University of Edinburgh"
},
{
    "Name": "Sam Tobin-Hochstadt",
    "Affiliation": "Northeastern University & PLT"
},
{
    "Name": "Samik Basu",
    "Affiliation": "Iowa State University"
},
{
    "Name": "Samir Genaim",
    "Affiliation": "Complutense University of Madrid"
},
{
    "Name": "Santiago Zanella Beguelin",
    "Affiliation": "IMDEA Software Institute"
},
{
    "Name": "Santosh Nagarakatte",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "Sasa Misailovic",
    "Affiliation": "MIT"
},
{
    "Name": "Saurabh Joshi",
    "Affiliation": "IIT Kanpur"
},
{
    "Name": "Scott Owens",
    "Affiliation": "University of Cambridge"
},
{
    "Name": "Scott Stoller",
    "Affiliation": "State University of New York at Stony Brook"
},
{
    "Name": "Sergio Maffeis",
    "Affiliation": "Imperial College"
},
{
    "Name": "Shuvendu Lahiri",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Simon Peyton Jones",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Slawomir Lasota",
    "Affiliation": "University of Warsaw"
},
{
    "Name": "Sooraj Bhat",
    "Affiliation": "Georgia Institute of Technology"
},
{
    "Name": "Stefan Blom",
    "Affiliation": "University of Twente and Dundalk Institute of Technology"
},
{
    "Name": "Stefan Wehr",
    "Affiliation": "University of Freiburg"
},
{
    "Name": "Stephan van Staden",
    "Affiliation": "ETH Zurich"
},
{
    "Name": "Stephanie Weirich",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "Steve Zdancewic",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "Sukyoung Ryu",
    "Affiliation": "KAIST"
},
{
    "Name": "Suresh Jagannathan",
    "Affiliation": "Purdue University"
},
{
    "Name": "Surinder Jain",
    "Affiliation": "The University of Sydney"
},
{
    "Name": "Susmit Sarkar",
    "Affiliation": "University of Cambridge"
},
{
    "Name": "Susumu Katayama",
    "Affiliation": "University of Miyazaki"
},
{
    "Name": "Tahina Ramananandro",
    "Affiliation": "INRIA Paris-Rocquencourt"
},
{
    "Name": "Takumi Goto",
    "Affiliation": "Shibaura Institute of Technology"
},
{
    "Name": "Tevfik Bultan",
    "Affiliation": "University of California, Santa Barbara"
},
{
    "Name": "Thibaut Balabonski",
    "Affiliation": "Univ Paris Diderot, Sorbonne Paris Cité, PPS, UMR 7126, CNRS"
},
{
    "Name": "Thomas Austin",
    "Affiliation": "University of California, Santa Cruz"
},
{
    "Name": "Tiark Rompf",
    "Affiliation": "EPFL"
},
{
    "Name": "Tim Sheard",
    "Affiliation": "Portland State University"
},
{
    "Name": "Tom Rothamel",
    "Affiliation": "State University of New York at Stony Brook"
},
{
    "Name": "Tony Hoare",
    "Affiliation": "Microsoft Research"
},
{
    "Name": "Uday Reddy",
    "Affiliation": "University of Birmingham"
},
{
    "Name": "Viktor Kuncak",
    "Affiliation": "Swiss Federal Institute of Technology (EPFL)"
},
{
    "Name": "Viktor Vafeiadis",
    "Affiliation": "MPI-SWS"
},
{
    "Name": "Vilhelm Sjoberg",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "Vilhelm Sjöberg",
    "Affiliation": "University of Pennsylvania"
},
{
    "Name": "Vlad Ureche",
    "Affiliation": "EPFL"
},
{
    "Name": "Vladimir Komendantsky",
    "Affiliation": "University of St Andrews"
},
{
    "Name": "Xavier Leroy",
    "Affiliation": "INRIA Paris-Rocquencourt"
},
{
    "Name": "Xiaokang Qiu",
    "Affiliation": "University of Illinois at Urbana-Champaign"
},
{
    "Name": "Xinyu Feng",
    "Affiliation": "University of Science and Technology of China"
},
{
    "Name": "Yanhong Liu",
    "Affiliation": "State University of New York at Stony Brook"
},
{
    "Name": "Yannis Smaragdakis",
    "Affiliation": "University of Athens and University of Massachusetts"
},
{
    "Name": "Yutaka Oiwa",
    "Affiliation": "National Institute of Advanced Industrial Science and Technology"
},
{
    "Name": "Zachary Kincaid",
    "Affiliation": "University of Toronto"
},
{
    "Name": "Zeyuan Zhu",
    "Affiliation": "MIT"
},
{
    "Name": "Zhong Shao",
    "Affiliation": "Yale University"
},
{
    "Name": "Zoltan Somogyi",
    "Affiliation": "The University of Melbourne & National ICT Australia (NICTA)"
}
	]
});